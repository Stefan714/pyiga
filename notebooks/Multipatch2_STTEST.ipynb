{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a79efc12-f80d-4be3-b107-4a7ec2e821af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import scipy\n",
    "import sys\n",
    "from scipy.sparse import coo_matrix, block_diag, identity, hstack\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from pyiga import bspline, vform, geometry, vis, solvers, utils\n",
    "from pyiga import assemble as Ass\n",
    "from patchmesh import *\n",
    "from patchmesh3D import *\n",
    "import itertools as it\n",
    "#from multipatch import *\n",
    "\n",
    "numpy.set_printoptions(linewidth=100000)\n",
    "numpy.set_printoptions(precision=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b22d4f2-ab7a-46d8-9e12-9894a3d0cca1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rref(A, tol=1e-8):\n",
    "    B=A.astype(float).copy()\n",
    "    m,n=B.shape\n",
    "    rows=np.arange(m)\n",
    "    i=0\n",
    "    j=0\n",
    "    piv=[]  #indices of pivot columns, rank = length(piv)\n",
    "    while (i<m and j<n):\n",
    "        k = np.argmax(abs(B[i:m,j]))\n",
    "        k=k+i\n",
    "        if abs(B[k,j])<=tol:\n",
    "            B[i:m,j]=0\n",
    "            j+=1\n",
    "        else:\n",
    "            piv.append(j)\n",
    "            if k!=i:\n",
    "                rows[[i,k]]=rows[[k,i]]\n",
    "                B[[i,k],j:n]=B[[k,i],j:n]\n",
    "            B[i,j:n]=B[i,j:n]/B[i,j]\n",
    "            for l in np.r_[np.arange(i),np.arange(i+1,m)]:\n",
    "                B[l,j:n]=B[l,j:n]-B[l,j]*B[i,j:n]\n",
    "            i+=1\n",
    "            j+=1\n",
    "    return B, np.array(piv), rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cca4f286-0e9b-4014-8710-aec94a720fa3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def basis_for_nullspace_of_dense_SVD(constr):\n",
    "    '''Derives a matrix representing a basis for the nullspace of a dense matrix using SVD'''\n",
    "    result = scipy.linalg.null_space(constr)\n",
    "    # Scaling: Largest entry should be 1\n",
    "    for i in range(result.shape[1]):\n",
    "        mx = result[:,i].max()\n",
    "        mn = result[:,i].min()\n",
    "        if mx > -mx:\n",
    "            result[:,i] /= mx\n",
    "        else:\n",
    "            result[:,i] /= mn\n",
    "    return result.transpose()\n",
    "\n",
    "def basis_for_nullspace_of_dense_LU(constr, tol=1e-8):\n",
    "    '''Derives a matrix representing a basis for the nullspace of a dense matrix using LU'''\n",
    "    #P,L,U = scipy.linalg.lu(constr)\n",
    "    U, piv, _ = rref(constr, tol=tol)\n",
    "    # Remove (almost) empty rows\n",
    "    U=U[:len(piv),:]\n",
    "    r,c = U.shape\n",
    "    #print(U)\n",
    "    # Swap cols if necessary\n",
    "    perm = np.arange(c)\n",
    "    for i in range(len(piv)):\n",
    "        perm[[i,piv[i]]]=perm[[piv[i],i]]\n",
    "#     for i in range(r):\n",
    "#         if abs(U[i,i])<tol:\n",
    "#             #mx = np.abs(U[i,i+1:]).max()\n",
    "#             j = i\n",
    "#             while abs(U[i,j]) < tol:\n",
    "#                  j += 1\n",
    "# #             j=i\n",
    "# #             while abs(U[i,j])<tol:\n",
    "# #                 j+=1\n",
    "#             perm[i], perm[j] = perm[j], perm[i]\n",
    "#             U[:,[i,j]] = U[:,[j,i]]\n",
    "    # Split matrix U and resolve linear system\n",
    "    #print(U)\n",
    "    U1 = U[:,piv]\n",
    "    U2 = U[:,perm[len(piv):]]\n",
    "    #print(U1)\n",
    "    #sol = scipy.linalg.lu_solve((U1,np.arange(r)),U2)\n",
    "    # Setup result\n",
    "    result = np.zeros((c,c-r))\n",
    "    result[:r,:] = -U2\n",
    "    result[r:,:] = np.eye(c-r)    \n",
    "    # Apply perm\n",
    "    result2=result.copy()\n",
    "    result[list(perm)] = result2\n",
    "    # Scaling: Largest entry should be 1\n",
    "    for i in range(result.shape[1]):\n",
    "        mx = result[:,i].max()\n",
    "        mn = result[:,i].min()\n",
    "        if mx > -mx:\n",
    "            result[:,i] /= mx\n",
    "        else:\n",
    "            result[:,i] /= mn\n",
    "    #R, piv, row_exchanges = rref(result.T)\n",
    "    return result.T\n",
    "\n",
    "def get_connected_components(constr):\n",
    "    '''Derives all connected components of the graph, where cols of matrix are nodes'''\n",
    "    assert isinstance(constr, scipy.sparse.csr_matrix)\n",
    "    (r, c) = constr.shape\n",
    "    \n",
    "    if not constr.has_sorted_indices:\n",
    "        constr.sort_indices()\n",
    "    \n",
    "    comps = np.arange(c)\n",
    "    for i in range(r):\n",
    "        smallest_index = c\n",
    "        for j in range(constr.indptr[i], constr.indptr[i+1]):\n",
    "            smallest_index = min(smallest_index, comps[constr.indices[j]])\n",
    "        for j in range(constr.indptr[i], constr.indptr[i+1]):\n",
    "            idx=comps[constr.indices[j]]\n",
    "            comps[constr.indices[j]]=smallest_index\n",
    "            while comps[idx]>smallest_index:\n",
    "                idx_new=comps[idx]\n",
    "                comps[idx] = smallest_index\n",
    "                idx=comps[idx_new]\n",
    "    \n",
    "    for i in range(c):\n",
    "        if comps[comps[i]] < comps[i]:\n",
    "            comps[i] = comps[comps[i]]\n",
    "        \n",
    "    constr_list = {}\n",
    "    for i in range(r):\n",
    "        comp = comps[constr.indices[constr.indptr[i]]]\n",
    "        if comp not in constr_list:\n",
    "            constr_list[comp] = []         \n",
    "        constr_list[comp].append(i)\n",
    "        \n",
    "    comp_list = {}\n",
    "    coupled = np.zeros(c,'b')\n",
    "    for i in range(c):\n",
    "        comp = comps[i]\n",
    "        if comp != i or comp in constr_list.keys():\n",
    "            if not comp in comp_list:\n",
    "                comp_list[comp] = [comp]\n",
    "            if comp != i:\n",
    "                comp_list[comp].append(i)\n",
    "            coupled[i] = True\n",
    "    \n",
    "#     print(\"coupled     =\",coupled)\n",
    "#     print(\"comp_list   =\",comp_list)\n",
    "#     print(\"constr_list =\",constr_list)\n",
    "    \n",
    "    return coupled, comp_list, constr_list\n",
    "\n",
    "def basis_for_nullspace(constr, basis_for_nullspace_of_dense=basis_for_nullspace_of_dense_SVD):\n",
    "    '''Derives a matrix representing a basis for the nullspace of a sparse matrix by first decomposing it into its connected components'''\n",
    "    assert isinstance(constr, scipy.sparse.csr_matrix)\n",
    "    (r, c) = constr.shape\n",
    "    \n",
    "    coupled, comp_list, constr_list = get_connected_components(constr)\n",
    "\n",
    "    mat = scipy.sparse.lil_matrix((c,c))\n",
    "    \n",
    "    # First, take the free dofs as they are\n",
    "    row = 0\n",
    "    for i in range(c):\n",
    "        if not coupled[i]:\n",
    "            mat[row,i] = 1\n",
    "            row += 1\n",
    "\n",
    "    # TODO: Secondly, take the dofs with one-to-one mapping\n",
    "    \n",
    "    # Finally, take the other dofs\n",
    "    for i in comp_list.keys():\n",
    "        comp_item = comp_list[i]\n",
    "        constr_item = constr_list[i]\n",
    "        local_matrix = (constr[constr_item,:][:,comp_item]).A\n",
    "        #print(local_matrix)\n",
    "        local_basis  = basis_for_nullspace_of_dense(local_matrix)\n",
    "        #print(local_basis)\n",
    "        #print( \"local_matrix:\\n\", local_matrix )\n",
    "        #print( \"local_basis :\\n\", local_basis  )\n",
    "        lb_rows, lb_cols = local_basis.shape\n",
    "        for i0 in range(lb_rows):\n",
    "            for j0 in range(lb_cols):\n",
    "                mat[row,comp_item[j0]] = local_basis[i0,j0]\n",
    "            row += 1\n",
    "\n",
    "    mat.resize(row,c)\n",
    "    return mat.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3986e24-4539-418c-93b3-42e7f62283b8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def PoissonEstimator(MP,f,uh):\n",
    "    n = MP.mesh.numpatches\n",
    "    indicator = np.zeros(n)\n",
    "    params = {'f': f}\n",
    "    \n",
    "    uh_per_patch = dict()\n",
    "    \n",
    "    #residual contribution\n",
    "    for p, ((kvs, geo), _) in enumerate(MP.mesh.patches):\n",
    "        \n",
    "        h = np.linalg.norm([b-a for a,b in geo.bounding_box()])\n",
    "        \n",
    "        N = tuple(kv.numdofs for kv in kvs)\n",
    "        uh_per_patch[p] = (MP.global_to_patch(p) @ uh).reshape(N)   #cache Spline Function on patch p\n",
    "        \n",
    "        params['geo'] = geo\n",
    "        params['uh_func'] = geometry.BSplineFunc(kvs, uh_per_patch[p])\n",
    "        \n",
    "        kvs0 = tuple([bspline.KnotVector(kv.mesh, 0) for kv in kvs])\n",
    "        indicator[p] = h**2 * np.sum(Ass.assemble('(f + div(grad(uh_func)))**2 * v * dx', kvs0, params))\n",
    "        \n",
    "    params = dict()\n",
    "    \n",
    "    #flux contribution\n",
    "    for i,((p1,b1,_), (p2,b2,_), _, flip) in enumerate(MP.intfs):\n",
    "        #print(p1, p2, flip)\n",
    "        \n",
    "        ((kvs1, geo1), _), ((kvs2, geo2), _) = MP.mesh.patches[p1], MP.mesh.patches[p2]\n",
    "        bdspec1, bdspec2 = Ass.int_to_bdspec(b1), Ass.int_to_bdspec(b2)\n",
    "        \n",
    "        bkv1, bkv2 = Ass.boundary_kv(kvs1, bdspec1), Ass.boundary_kv(kvs2, bdspec2)\n",
    "\n",
    "        geo = geo2.boundary(bdspec2)\n",
    "        params['geo'] = geo\n",
    "        \n",
    "        kv0 = tuple([bspline.KnotVector(kv.mesh, 0) for kv in bkv2])\n",
    "        h = np.sum(Ass.assemble('v * ds', kv0, params))\n",
    "        \n",
    "        params['uh_grad1'] = geometry.BSplineFunc(kvs1, uh_per_patch[p1]).transformed_jacobian(geo1).boundary(bdspec1, flip=flip) #physical gradient of uh on patch 1 (flipped if needed)\n",
    "        params['uh_grad2'] = geometry.BSplineFunc(kvs2, uh_per_patch[p2]).transformed_jacobian(geo2).boundary(bdspec2)            #physical gradient of uh on patch 2\n",
    "        #params['uh1'] = geometry.BSplineFunc(kvs1, uh_per_patch[p1]).boundary(bdspec1,flip=flip)\n",
    "        #params['uh2'] = geometry.BSplineFunc(kvs2, uh_per_patch[p2]).boundary(bdspec2)\n",
    "        normalflux_jump = np.sum(Ass.assemble('(inner(uh_grad1 - uh_grad2, n) )**2 * v * ds', kv0 ,params))\n",
    "        #print(normalflux_jump)\n",
    "\n",
    "        indicator[p1] += 0.5 * h * normalflux_jump\n",
    "        indicator[p2] += 0.5 * h * normalflux_jump\n",
    "    \n",
    "    return np.sqrt(indicator)\n",
    "\n",
    "def check_coupling(MP, u_):\n",
    "    u_pp = dict()\n",
    "\n",
    "    for i,((p1,b1,_), (p2,b2,_), flip) in enumerate(MP.intfs):\n",
    "        \n",
    "        ((kvs1,_),_), ((kvs2,_),_) = MP.mesh.patches[p1], MP.mesh.patches[p2]\n",
    "        bdspec1, bdspec2 = int_to_bdspec(b1), int_to_bdspec(b2)\n",
    "        (kv1), (kv2) = boundary_kv(kvs1, bdspec1), boundary_kv(kvs2, bdspec2, flip=flip)\n",
    "        dofs1, dofs2 = Ass.boundary_dofs(kvs1, bdspec1, ravel=True), Ass.boundary_dofs(kvs2, bdspec2, ravel=True, flip=flip)\n",
    "        \n",
    "        if p1 not in u_pp:\n",
    "            u_pp[p1]=MP.global_to_patch(p1) @ u_\n",
    "        if p2 not in u_pp:\n",
    "            u_pp[p2]=MP.global_to_patch(p2) @ u_\n",
    "          \n",
    "        P = bspline.prolongation(kv1, kv2)\n",
    "        u1, u2 = u_pp[p1][dofs1], u_pp[p2][dofs2]\n",
    "        r=norm(u2 - P @ u1)\n",
    "        \n",
    "        if r>1e-8:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "class Multipatch:\n",
    "    \"\"\"Represents a multipatch structure, consisting of a number of patches\n",
    "    together with their discretizations and the information about shared dofs\n",
    "    between patches. Nonconforming patches (both geometrically and knotwise non conforming) are allowed as long as there exists \n",
    "    a hierarchy between the interface knots\n",
    "\n",
    "    Args:\n",
    "        pm: A :class:`PatchMesh` instance representing the patches \n",
    "            via their discretization and their geometry function \n",
    "            as well as the generated mesh between the patches (vertices, interfaces).\n",
    "            \n",
    "        b_data: A dictionary of the form {'D':dir_data, 'N':neu_data, 'R': robin_data}\n",
    "            dir_data: A list of triples (patch, bdspec, dir_func) prescribing the function `dir_func` to boundary dofs of `patch` on side `bdspec`.\n",
    "            neu_data: A list of triples (patch, bdspec, neu_func) in order to assemble natural boundary conditions for boundary dofs of `patch` on side `bdspec`.\n",
    "            robin_data: A list of triples (patch, bd_spec, (gamma, robin_func))\n",
    "        \n",
    "        automatch (bool): if True, attempt to automatically apply the interface information from the PatchMesh object to couple the patches.\n",
    "            If False, the user has to manually join the patches by calling\n",
    "            :meth:`join_boundaries` as often as needed, followed by\n",
    "            :meth:`finalize`.\n",
    "    \"\"\"\n",
    "    def __init__(self, pm, automatch=False, dim=2):\n",
    "        \"\"\"Initialize a multipatch structure.\"\"\"\n",
    "        # underlying PatchMesh object describing the geometry\n",
    "        self.mesh = pm\n",
    "        # enforced regularity across patch interfaces\n",
    "        #self.k = k\n",
    "        self.dim = dim \n",
    "            \n",
    "        # number of tensor product dofs per patch\n",
    "        self.n = [tuple([kv.numdofs for kv in kvs]) for ((kvs,_),_) in self.mesh.patches]\n",
    "        self.N = [np.prod(n) for n in self.n]\n",
    "        # offset to the dofs of the i-th patch\n",
    "        self.N_ofs = np.concatenate(([0], np.cumsum(self.N)))\n",
    "        # per patch, a dict of shared indices\n",
    "        self.shared_pp = dict(zip([p for p in range(self.mesh.numpatches)],self.mesh.numpatches*[set(),]))\n",
    "        # a list of interfaces (patch1, boundary dofs1, patch2, boundary dofs2)\n",
    "        self.intfs = set()\n",
    "        self.Constr=scipy.sparse.csr_matrix((0,self.N_ofs[-1]))\n",
    "        self.dof_class={dof:0 for dof in np.arange(self.N_ofs[-1])}\n",
    "\n",
    "        if automatch:\n",
    "            interfaces = self.mesh.interfaces.copy()\n",
    "            \n",
    "            for ((p1,bd1,s1),((p2,bd2,s2),flip)) in interfaces.items():\n",
    "                if ((p2,bd2,s2),(p1,bd1,s1),flip) not in self.intfs:\n",
    "                    self.intfs.add(((p1,bd1,s1),(p2,bd2,s2),flip))\n",
    "                \n",
    "            #print(self.intfs)\n",
    "            for ((p1,bd1,s1),(p2,bd2,s2), flip) in self.intfs:\n",
    "                bdspec1 = (Ass.int_to_bdspec(bd1),)\n",
    "                bdspec2 = (Ass.int_to_bdspec(bd2),)\n",
    "                self.join_boundaries(p1, bdspec1, s1 , p2, bdspec2, s2, flip)\n",
    "            #self.finalize()\n",
    "\n",
    "    @property\n",
    "    def numpatches(self):\n",
    "        \"\"\"Number of patches in the multipatch structure.\"\"\"\n",
    "        return len(self.mesh.patches)\n",
    "\n",
    "    @property\n",
    "    def numdofs(self):\n",
    "        \"\"\"Number of dofs after eliminating shared dofs.\n",
    "\n",
    "        May only be called after :func:`finalize`.\n",
    "        \"\"\"\n",
    "        return self.Basis.shape[0]\n",
    "    \n",
    "    @property\n",
    "    def numloc_dofs(self):\n",
    "        return self.N_ofs[-1]\n",
    "    \n",
    "    def reset(self, automatch = False):\n",
    "        self.__init__(pm=self.mesh, b_data=self.b_data, dim=self.dim, automatch=automatch)\n",
    "\n",
    "    def join_boundaries(self, p1, bdspec1, s1, p2, bdspec2, s2, flip=None):\n",
    "        \"\"\"Join the dofs lying along boundary `bdspec1` of patch `p1` with\n",
    "        those lying along boundary `bdspec2` of patch `p2`. \n",
    "\n",
    "        See :func:`compute_dirichlet_bc` for the format of the boundary\n",
    "        specification.\n",
    "\n",
    "        If `flip` is given, it should be a sequence of booleans indicating for\n",
    "        each coordinate axis of the boundary if the coordinates of `p2` have to\n",
    "        be flipped along that axis.\n",
    "        \"\"\"\n",
    "        \n",
    "        kvs1, kvs2 = self.mesh.patches[p1][0][0], self.mesh.patches[p2][0][0]\n",
    "        if flip is None:\n",
    "            flip=(self.dim-1)*(False,)\n",
    "        \n",
    "        bkv1 = Ass.boundary_kv(kvs1, bdspec1)\n",
    "        bkv2 = Ass.boundary_kv(kvs2, bdspec2, flip=flip) \n",
    "        \n",
    "        #retrieve local dofs for each patch on the boundary\n",
    "        dofs1 = Ass.boundary_dofs(self.mesh.patches[p1][0][0], bdspec1, ravel=True)\n",
    "        dofs2 = Ass.boundary_dofs(self.mesh.patches[p2][0][0], bdspec2, ravel=True, flip=flip)\n",
    "                \n",
    "        #check for hierarchy of the boundary knot vectors. currently only supports knot vectors with equal degree.\n",
    "        if all([bspline.is_sub_space(kv1,kv2) for kv1, kv2 in zip(bkv1,bkv2)]):\n",
    "            pass\n",
    "        elif all([bspline.is_sub_space(kv2,kv1) for kv1, kv2 in zip(bkv1,bkv2)]):          \n",
    "            p1, p2 = p2, p1\n",
    "            bdspec1, bdspec2 = bdspec2, bdspec1\n",
    "            bkv1, bkv2 = bkv2, bkv1\n",
    "            dofs1, dofs2 = dofs2, dofs1\n",
    "        else:\n",
    "            print('interface coupling not possible')\n",
    "            \n",
    "        for dof in dofs1:\n",
    "            if self.dof_class[dof + self.N_ofs[p1]]==0:\n",
    "                self.dof_class[dof + self.N_ofs[p1]]=1\n",
    "        for dof in dofs2:\n",
    "            self.dof_class[dof + self.N_ofs[p2]]=2\n",
    "            \n",
    "        self.shared_pp[p1]=self.shared_pp[p1] | set(dofs1)\n",
    "        self.shared_pp[p2]=self.shared_pp[p2] | set(dofs2)\n",
    "            \n",
    "        #Prolongation operator  \n",
    "        P = -scipy.sparse.coo_matrix(bspline.prolongation_tp(bkv1,bkv2))   #TODO: make paramater to generate prolongation matrix as coo_matrix directly?\n",
    "        #construct constraints for this interface\n",
    "        data = np.concatenate([P.data, np.ones(len(dofs2))])\n",
    "        I = np.concatenate([P.row, np.arange(len(dofs2))])\n",
    "        J = np.concatenate([dofs1[P.col] + self.N_ofs[p1],dofs2 + self.N_ofs[p2]])\n",
    "        \n",
    "        self.Constr = scipy.sparse.vstack([self.Constr,scipy.sparse.coo_matrix((data,(I,J)),(len(dofs2), self.numloc_dofs)).tocsr()])\n",
    "        \n",
    "           \n",
    "    def finalize(self):\n",
    "        \"\"\"After all shared dofs have been declared using\n",
    "        :meth:`join_boundaries` or :meth:`join_dofs`, call this function to set\n",
    "        up the internal data structures.\n",
    "        \"\"\"\n",
    "        num_shared = [len(self.shared_pp[p]) for p in range(self.numpatches)]\n",
    "        # number of local dofs per patch\n",
    "        self.M = [n - s for (n, s) in zip(self.N, num_shared)]\n",
    "        # local-to-global offset per patch\n",
    "        self.M_ofs = np.concatenate(([0], np.cumsum(self.M)))\n",
    "        #TODO: self.Basis = basis_for_nullspace(self.Constr, basis_for_nullspace_of_dense_LU, idx=self.dof_class)\n",
    "        #self.sanity_check()   \n",
    "\n",
    "    def assemble_system(self, problem, rhs, args=None, bfuns=None,\n",
    "            symmetric=False, format='csr', layout='blocked', **kwargs):\n",
    "        \"\"\"Assemble both the system matrix and the right-hand side vector\n",
    "        for a variational problem over the multipatch geometry.\n",
    "\n",
    "        Here `problem` represents a bilinear form and `rhs` a linear functional.\n",
    "        See :func:`assemble` for the precise meaning of the arguments.\n",
    "\n",
    "        Returns:\n",
    "            A pair `(A, b)` consisting of the sparse system matrix and the\n",
    "            right-hand side vector.\n",
    "        \"\"\"\n",
    "        n = self.numdofs\n",
    "        X=MP.Basis\n",
    "        \n",
    "        A = []\n",
    "        b = []\n",
    "        if args is None:\n",
    "            args = dict()\n",
    "        for p in range(self.numpatches):\n",
    "            kvs, geo = self.mesh.patches[p][0]\n",
    "            args.update(geo=geo)\n",
    "            # TODO: vector-valued problems\n",
    "            A.append(Ass.assemble(problem, kvs, args=args, bfuns=bfuns,\n",
    "                    symmetric=symmetric, format=format, layout=layout,\n",
    "                    **kwargs))\n",
    "    \n",
    "            b.append(Ass.assemble(rhs, kvs, args=args, bfuns=bfuns,\n",
    "                    symmetric=symmetric, format=format, layout=layout,\n",
    "                    **kwargs).ravel())\n",
    "        A = X@scipy.sparse.block_diag(A)@X.T\n",
    "        b = X@np.concatenate(b)\n",
    "            \n",
    "        return A, b\n",
    "    \n",
    "    def assemble_surface(self, problem, arity=1, boundary_idx=0, args=None, bfuns=None,\n",
    "            symmetric=False, format='csr', layout='blocked', **kwargs):\n",
    "        X = MP.Basis\n",
    "        if args is None:\n",
    "            args = dict()\n",
    "        if arity==2:\n",
    "            I, J, data = [], [], []\n",
    "            for (p,b) in self.mesh.outer_boundaries[boundary_idx]:\n",
    "                kvs, geo = self.mesh.patches[p][0]\n",
    "                bdspec=[(b//2,b%2)]\n",
    "                bdofs = Ass.boundary_dofs(kvs, bdspec, ravel=True) + self.N_ofs[p]\n",
    "                args.update(geo = geo)\n",
    "                \n",
    "                R = Ass.assemble(problem, kvs, args=args, bfuns=bfuns,\n",
    "                        symmetric=symmetric, format='coo', layout=layout,\n",
    "                        **kwargs, boundary=bdspec)\n",
    "                \n",
    "                I_p ,J_p = R.row, R.col\n",
    "                I.append(bdofs[I_p]), J.append(bdofs[J_p]), data.append(R.data)\n",
    "                \n",
    "            I, J, data = np.concatenate(I), np.concatenate(J), np.concatenate(data)\n",
    "            R = scipy.sparse.coo_matrix((data, (I, J)), 2*(self.numloc_dofs,))\n",
    "            return X @ scipy.sparse.csr_matrix(R) @ X.T\n",
    "        else:\n",
    "            N=np.zeros(self.numloc_dofs)\n",
    "            for (p,b) in self.mesh.outer_boundaries[boundary_idx]:\n",
    "                kvs, geo = self.mesh.patches[p][0]\n",
    "                bdspec=[(b//2,b%2)]\n",
    "                bdofs = Ass.boundary_dofs(kvs, bdspec, ravel=True) + self.N_ofs[p]\n",
    "                args.update(geo = geo)\n",
    "    \n",
    "                vals=Ass.assemble(problem, kvs, args=args, bfuns=bfuns,\n",
    "                        symmetric=symmetric, format=format, layout=layout,\n",
    "                        **kwargs, boundary=bdspec).ravel()\n",
    "                N[bdofs] += vals \n",
    "            \n",
    "            return X @ N\n",
    "            \n",
    "    \n",
    "#     def assemble_boundary(self, problem, boundary_idx = None, args=None, bfuns=None,\n",
    "#             symmetric=False, format='csr', layout='blocked', **kwargs):\n",
    "        \n",
    "    \n",
    "#     def C1_coupling(self, p1, bdspec1, p2, bdspec2, flip=None):\n",
    "        \n",
    "#         (ax1, sd1), (ax2, sd2) = bdspec1, bdspec2\n",
    "#         ((kvs1, geo1),_), ((kvs2, geo2),_) = self.mesh.patches[p1], self.mesh.patches[p2]\n",
    "#         sup1, sup2 = geo1.support, geo2.support\n",
    "#         dim=len(kvs1)\n",
    "#         if flip is None:\n",
    "#             flip=(dim-1)*(False,)\n",
    " \n",
    "#         bkv1, bkv2 = Ass.boundary_kv(kvs1, bdspec1), Ass.boundary_kv(kvs2, bdspec2)\n",
    "#         dofs1, dofs2 = Ass.boundary_dofs(kvs1, bdspec1, ravel = True, k=1), Ass.boundary_dofs(kvs2, bdspec2, ravel = True, flip=flip, k=1)\n",
    "#         G = tuple(kv.greville() for kv in kvs2)\n",
    "#         G2 = G[:ax2] + (np.array([sup2[ax2][0] if sd2==0 else sup2[ax2][-1]]),) + G[ax2+1:]\n",
    "#         G1 = G[:ax2] + G[ax2+1:]\n",
    "#         G1 = G1[:ax1] + (np.array([sup1[ax1][0] if sd1==0 else sup1[ax1][-1]]),) + G1[ax1:] #still need to add flip\n",
    "\n",
    "#         M=tuple(len(g) for g in G2)\n",
    "#         m=np.prod(M)\n",
    "#         n1,n2=len(dofs1), len(dofs2)\n",
    "        \n",
    "#         C1, D1 = bspline.collocation_derivs_tp(kvs1, G1, derivs=1)\n",
    "#         C2, D2 = bspline.collocation_derivs_tp(kvs2, G2, derivs=1)\n",
    "    \n",
    "#         C1, C2 = C1[0].tocsr()[:,dofs1], C2[0].tocsr()[:,dofs2]\n",
    "#         for i in range(dim):\n",
    "#             D1[i], D2[i] = D1[i].tocsr()[:,dofs1], D2[i].tocsr()[:,dofs2]\n",
    "#         N2=geo2.boundary(bdspec2).grid_outer_normal(G2[:ax2]+G2[ax2+1:]).reshape(m,dim)\n",
    "\n",
    "#         J1=geo1.grid_jacobian(G1).reshape(m,dim,dim)\n",
    "#         J2=geo2.grid_jacobian(G2).reshape(m,dim,dim)\n",
    "        \n",
    "#         invJ1=np.array([inv(jac) for jac in J1[:]])\n",
    "#         invJ2=np.array([inv(jac) for jac in J2[:]])\n",
    "\n",
    "#         NC1=scipy.sparse.csr_matrix((m, n1))\n",
    "#         for i in range(dim):\n",
    "#             NC1_ = scipy.sparse.csr_matrix((m, n1))\n",
    "#             for j in range(dim):\n",
    "#                 NC1_ += scipy.sparse.spdiags(invJ1[:,i,j], 0, m, m)*D1[dim-1-j]\n",
    "#             NC1 += scipy.sparse.spdiags(N2[:,i], 0, m, m)*NC1_\n",
    "            \n",
    "#         NC2=scipy.sparse.csr_matrix((m, n2))\n",
    "#         for i in range(dim):\n",
    "#             NC2_ = scipy.sparse.csr_matrix((m, n2))\n",
    "#             for j in range(dim):\n",
    "#                 NC2_ += scipy.sparse.spdiags(invJ2[:,i,j], 0, m, m)*D2[dim-1-j]\n",
    "#             NC2 += scipy.sparse.spdiags(N2[:,i], 0, m, m)*NC2_\n",
    "            \n",
    "#         A = scipy.sparse.vstack([C1, NC1])\n",
    "#         B = scipy.sparse.vstack([C2, NC2])\n",
    "#         P = scipy.sparse.linalg.spsolve(B,A.A)\n",
    "#         # prune matrix\n",
    "#         P[np.abs(P) < 1e-15] = 0.0\n",
    "#         return scipy.sparse.csr_matrix(P) \n",
    "        \n",
    "    def L2Projection(self, u):\n",
    "        M, rhs, _, _, _ = self.assemble_system(vform.mass_vf(2), vform.L2functional_vf(2, physical=True), f=u)\n",
    "        u_ = solvers.make_solver(M, spd=True).dot(rhs)\n",
    "        return u_\n",
    "    \n",
    "    def refine(self, patches=None, mult=1, return_prol=False):\n",
    "        if isinstance(patches, dict):\n",
    "            assert max(patches.keys())<self.numpatches and min(patches.keys())>=0, \"patch index out of bounds.\"\n",
    "            patches = patches.keys()\n",
    "        elif isinstance(patches, (list, set, np.ndarray)):\n",
    "            assert max(patches)<self.numpatches and min(patches)>=0, \"patch index out of bounds.\"\n",
    "        elif patches==None:\n",
    "            patches = np.arange(self.numpatches)\n",
    "        elif np.isscalar(patches):\n",
    "            patches=(patches,)\n",
    "        else:\n",
    "            assert 0, \"unknown input type\"\n",
    "        if return_prol:\n",
    "            n=self.numdofs\n",
    "            old_kvs=[kvs for (kvs,_),_ in self.mesh.patches]\n",
    "            old_global_to_patch = [self.global_to_patch(p) for p in range(self.numpatches)]\n",
    "            \n",
    "        self.mesh.refine(patches, mult=mult)\n",
    "        self.reset(automatch=True)\n",
    "        #MP = Multipatch(self.mesh, automatch=True, k=self.k)\n",
    "        \n",
    "        if return_prol:\n",
    "            m = self.numdofs\n",
    "            P = scipy.sparse.csr_matrix((m, n))\n",
    "            \n",
    "            for p in range(self.numpatches):\n",
    "                if p in patches:\n",
    "                    kvs=old_kvs[p]\n",
    "                    new_kvs=MP.mesh.patches[p][0][0]\n",
    "                    C = bspline.prolongation_tp(kvs, new_kvs)\n",
    "                else:\n",
    "                    C = scipy.sparse.identity(self.N[p])\n",
    "\n",
    "                P += MP.patch_to_global(p) @ C @ old_global_to_patch[p]\n",
    "            factors = [1/sum([sum(dof[p][1]) for p in dof]) for dof in MP.shared_dofs]\n",
    "            P[MP.M_ofs[-1]:] = scipy.sparse.spdiags(factors, 0, len(factors), len(factors)) @ P[MP.M_ofs[-1]:]\n",
    "            return P\n",
    "        \n",
    "    def patch_refine(self, patches=None, mult=1, return_prol = False):\n",
    "        \"\"\"Refines the Mesh by splitting patches\n",
    "        \n",
    "        The dictionary `patches` specifies which patches (dict keys) are to be split \n",
    "        and how to split them (dict values: 0 to dim-1 or None)\n",
    "        \n",
    "        The `return_prol` keyword enables also the generation of a prolongation matrix from one mesh to the split mesh.\n",
    "        \n",
    "        Returns:\n",
    "            A new :class:`Multipatch` object `MP`\n",
    "            A sparse matrix `P` suitable for prolongation.\n",
    "        \"\"\"\n",
    "        if isinstance(patches, dict):\n",
    "            assert max(patches.keys())<self.numpatches and min(patches.keys())>=0, \"patch index out of bounds.\"\n",
    "        elif isinstance(patches,int):\n",
    "            #assert patches >=0 and patches < self.dim, \"dimension error.\"\n",
    "            patches = {p:patches for p in range(self.numpatches)}\n",
    "        elif isinstance(patches, (list, set, np.ndarray)):\n",
    "            assert max(patches)<self.numpatches and min(patches)>=0, \"patch index out of bounds.\"\n",
    "            patches = {p:None for p in patches}\n",
    "        elif patches==None:\n",
    "            patches = {p:None for p in range(self.numpatches)}\n",
    "        else:\n",
    "            assert 0, \"unknown input type\"\n",
    "        \n",
    "        #n=self.numdofs\n",
    "        N=self.numpatches\n",
    "\n",
    "        #M = copy.deepcopy(self.mesh)\n",
    "        #old_kvs = [kvs for (kvs,_),_ in self.mesh.patches]\n",
    "       # old_global_to_patch = [self.global_to_patch(p) for p in range(self.numpatches)]\n",
    "        \n",
    "        new_patches = dict()\n",
    "        new_kvs_ = dict()\n",
    "        for p in patches.keys():\n",
    "            self.split_boundary_data(p, self.numpatches, axis=patches[p])\n",
    "            new_patches[p], new_kvs_[p] = self.mesh.split_patch(p, axis=patches[p], mult=mult)\n",
    "        \n",
    "        #MP = Multipatch(self.mesh, automatch=True, k=self.k)\n",
    "        self.reset(automatch=True)\n",
    "        #m = self.numdofs\n",
    "        \n",
    "        if return_prol:\n",
    "            P = scipy.sparse.csr_matrix((m, n))\n",
    "            for p in range(N):\n",
    "                kvs=old_kvs[p]\n",
    "                if p in new_patches:\n",
    "                    new_kvs = new_kvs_[p]\n",
    "                    S = scipy.sparse.csr_matrix((m,bspline.numdofs(new_kvs)))\n",
    "                    C =  bspline.prolongation_tp(kvs, new_kvs)\n",
    "                    \n",
    "                    for i, new_p in enumerate(new_patches[p]):\n",
    "                    \n",
    "                        val = np.ones(self.N[new_p])\n",
    "                        I = np.arange(self.N[new_p])\n",
    "                        \n",
    "                        if patches[p]==0:\n",
    "                            bdspec = (0,i)\n",
    "                            k = self.mesh.patches[new_p][0][0][0].numdofs\n",
    "                            J = np.sort(Ass.boundary_dofs(new_kvs,bdspec,ravel=True,k=k-1))\n",
    "                        elif patches[p]==1:\n",
    "                            bdspec = (1,i)\n",
    "                            k = self.mesh.patches[new_p][0][0][1].numdofs\n",
    "                            J = np.sort(Ass.boundary_dofs(new_kvs,bdspec,ravel=True,k=k-1))\n",
    "                        else:\n",
    "                            cspec=(i//2,i%2)\n",
    "                            k0=self.mesh.patches[new_p][0][0][0].numdofs\n",
    "                            k1=self.mesh.patches[new_p][0][0][1].numdofs\n",
    "                            J = np.sort(Ass.boundary_dofs(new_kvs,cspec,k=[k0-1,k1-1], ravel=True))\n",
    "               \n",
    "                        R = scipy.sparse.coo_matrix((val,(I,J)),shape=(self.N[new_p],bspline.numdofs(new_kvs)))\n",
    "                        S += self.patch_to_global(new_p) @ R\n",
    "                else:\n",
    "                    S=self.patch_to_global(p)\n",
    "                    C=scipy.sparse.identity(self.N[p])\n",
    "                \n",
    "                P += S @ C @ old_global_to_patch[p]\n",
    "                \n",
    "            factors = [1/sum([sum(dof[p][1]) for p in dof]) for dof in self.shared_dofs]\n",
    "            P[self.M_ofs[-1]:] = scipy.sparse.spdiags(factors, 0, len(factors), len(factors)) @ P[self.M_ofs[-1]:]\n",
    "            return P\n",
    "        \n",
    "#     def split_boundary_data(self, p, n, axis = None):\n",
    "#         \"\"\"Splits the boundary information of a patch `p`.\n",
    "    \n",
    "#         Args:\n",
    "#             p: patch to be split\n",
    "#             n: total number of patches\n",
    "#             dir_data: information of the Dirichlet condition over the whole PatchMesh structure\n",
    "            \n",
    "#         Returns:\n",
    "#             Modified list `dir_data` with split patches.\n",
    "#         \"\"\"\n",
    "#         if axis==None:\n",
    "#             axis=tuple(range(self.dim))\n",
    "#         axis=np.unique(axis)\n",
    "#         if len(axis)==1: axis=axis[0]\n",
    "#         for s in self.b_data.keys():\n",
    "            \n",
    "#             b_data_p = [(patch , bd, g) for (patch, bd, g) in self.b_data[s] if patch == p]\n",
    "            \n",
    "#             if b_data_p:\n",
    "#                 if not np.isscalar(axis):\n",
    "#                     for k,ax in enumerate(axis[::-1]):\n",
    "#                         self.split_boundary_data(p, n+2**k-1, axis=ax)\n",
    "#                         for i in range(2**k-1):\n",
    "#                             self.split_boundary_data(n+i, n+2**k+i, axis=ax)\n",
    "#                 else:\n",
    "#                     for (patch, bd, g) in b_data_p:\n",
    "#                         if self.dim==3:\n",
    "#                             if axis == self.dim - 3:\n",
    "#                                 if bd == 'back':\n",
    "#                                     self.b_data[s].remove((patch, bd, g))\n",
    "#                                     self.b_data[s].append((n, bd, g))\n",
    "#                                 if bd == 'left' or bd == 'right' or bd == 'bottom' or bd=='top':\n",
    "#                                     self.b_data[s].append((n, bd, g))\n",
    "#                         if axis == self.dim - 2:\n",
    "#                             if bd == 'top':\n",
    "#                                 self.b_data[s].remove((patch, bd, g))\n",
    "#                                 self.b_data[s].append((n, bd, g))\n",
    "#                             if bd == 'left' or bd == 'right':\n",
    "#                                 self.b_data[s].append((n, bd, g))\n",
    "#                             if self.dim == 3:\n",
    "#                                 if bd == 'front' or bd == 'back':\n",
    "#                                     self.b_data[s].append((n, bd, g)) \n",
    "#                         if axis == self.dim - 1:\n",
    "#                             if bd == 'right':\n",
    "#                                 self.b_data[s].remove((patch, bd, g))\n",
    "#                                 self.b_data[s].append((n, bd, g))   \n",
    "#                             if bd == 'bottom' or bd == 'top':\n",
    "#                                 self.b_data[s].append((n, bd, g))\n",
    "#                             if self.dim == 3:\n",
    "#                                 if bd == 'front' or bd == 'back':\n",
    "#                                     self.b_data[s].append((n, bd, g)) \n",
    "\n",
    "    def compute_dirichlet_bcs(self):\n",
    "        \"\"\"Performs the same operation as the global function\n",
    "        :func:`compute_dirichlet_bcs`, but for a multipatch problem.\n",
    "\n",
    "        The sequence `dir_data` should contain triples of the form `(patch,\n",
    "        bdspec, dir_func)`.\n",
    "\n",
    "        Returns:\n",
    "            A pair `(indices, values)` suitable for passing to\n",
    "            :class:`RestrictedLinearSystem`.\n",
    "        \"\"\"\n",
    "        bcs = []\n",
    "        p2g = dict()        # cache the patch-to-global indices for efficiency\n",
    "        for (p, bdspec, g) in self.b_data['D']:\n",
    "            (kvs, geo), _ = self.mesh.patches[p]\n",
    "            bc = Ass.compute_dirichlet_bc(kvs, geo, bdspec, g)\n",
    "            if p not in p2g:\n",
    "                p2g[p] = self.patch_to_global_idx(p)\n",
    "            idx = p2g[p]    # maps local dofs to global dofs\n",
    "            bcs.append((*idx[bc[0],0].toarray().T, bc[1]))\n",
    "        return Ass.combine_bcs(bcs)\n",
    "    \n",
    "    def sanity_check(self):\n",
    "        for p in range(self.numpatches):\n",
    "            assert all([np.isclose(sum(coeffs),1.0) for _,coeffs in self.shared_per_patch[p].values()]), 'coupling of dofs is flawed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78bd41c2-bea5-4835-aa60-730e77934e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elim_cycle(Constr, activeConstraints):\n",
    "    derivedDofs={}\n",
    "    for r in activeConstraints:\n",
    "        dofToBeEliminated = -1\n",
    "        feasible = True\n",
    "        for ind in range(Constr.indptr[r], Constr.indptr[r+1]):\n",
    "            c = Constr.indices[ind]\n",
    "            v = Constr.data[ind]\n",
    "            if v > 1e-14: # We know that there is only one (see assertion above!)\n",
    "                assert(dofToBeEliminated<0)\n",
    "                dofToBeEliminated = c\n",
    "        if dofToBeEliminated == -1: # Empty row (TODO: check)\n",
    "            feasible = False\n",
    "        for ind in range(Constr.indptr[r], Constr.indptr[r+1]):\n",
    "            c = Constr.indices[ind]\n",
    "            v = Constr.data[ind]\n",
    "            if v < -1e-14 and c in derivedDofs:\n",
    "                #print(\"{} cannot be eliminated (constraint #{}) because it refers to eliminated dof {}.\".format(dofToBeEliminated,r,c))\n",
    "                feasible = False\n",
    "        if dofToBeEliminated in derivedDofs:\n",
    "            #print(\"{} cannot be eliminated (constraint #{}) because it is already eliminated.\".format(dofToBeEliminated,r))\n",
    "            feasible = False\n",
    "        if feasible:\n",
    "            derivedDofs[dofToBeEliminated] = r\n",
    "    # for i, _ in derivedDofs.items():\n",
    "    #     print(i, end=', ')\n",
    "    return derivedDofs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8458bbd4-77e3-472c-b50b-ca8c10e717e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cycle_basis(Constr, derivedDofs, Basis):\n",
    "    n=Constr.shape[1]\n",
    "    testVec = np.zeros(n)\n",
    "    #print(Basis)\n",
    "    \n",
    "#Variant1\n",
    "#     lBasis = scipy.sparse.lil_matrix((n,n)) #coo_matrix ?\n",
    "#     for i in range(n):\n",
    "#         if not i in derivedDofs:\n",
    "#             lBasis[i,i] = 1\n",
    "\n",
    "#     for i, r in derivedDofs.items():\n",
    "#         for ind in range(Constr.indptr[r], Constr.indptr[r+1]):\n",
    "#             c = Constr.indices[ind]\n",
    "#             v = Constr.data[ind]    \n",
    "#             if v < -1e-12:\n",
    "#                 lBasis[i,c] = - v / Constr[r,i]\n",
    "    \n",
    "    ddofs=np.array(list(derivedDofs.keys()))   #derived dofs\n",
    "    n2 = len(ddofs)\n",
    "    r = np.array(list(derivedDofs.values()))  #which constraints do the dofs derive from\n",
    "    nddofs=np.setdiff1d(np.arange(n),ddofs)   #still free dofs\n",
    "    n1=len(nddofs)\n",
    "    \n",
    "#Variant2\n",
    "#     I=[nddofs]\n",
    "#     J=[nddofs]\n",
    "#     V = [np.ones(len(nddofs))]\n",
    "    \n",
    "#     for i, r in derivedDofs.items():\n",
    "#         idx = (Constr[r]<-1e-12)\n",
    "#         v = Constr[r].data[idx.indices]\n",
    "#         V.append(-v/Constr[r,i])\n",
    "#         I.append(np.repeat(i,len(v)))\n",
    "#         J.append(idx.indices)\n",
    "#     I=np.concatenate(I)\n",
    "#     J=np.concatenate(J)\n",
    "#     V=np.concatenate(V)\n",
    "#     print(len(I),len(J),len(V))\n",
    "#     lBasis = scipy.sparse.coo_matrix((V,(I,J)),shape=(n,n))\n",
    "\n",
    "#Variant3\n",
    "    lBasis=scipy.sparse.csr_matrix((n,n))\n",
    "    c = 1/(Constr[r,ddofs].A.ravel())\n",
    "    B1 = scipy.sparse.csr_matrix(scipy.sparse.coo_matrix((np.ones(n1),(np.arange(n1),nddofs)),(n1,n)))\n",
    "    B2 = - Constr[r].multiply(Constr[r]<0)\n",
    "    B2 = scipy.sparse.spdiags(c,0,n2,n2)@B2  #row scaling\n",
    "    \n",
    "    Q1 = scipy.sparse.coo_matrix((np.ones(n1),(nddofs,np.arange(n1))),(n,n1))\n",
    "    Q2 = scipy.sparse.coo_matrix((np.ones(n2),(ddofs,np.arange(n2))),(n,n2))\n",
    "    lBasis = Q1@B1 + Q2@B2\n",
    "    \n",
    "    lBasis = lBasis @ Basis\n",
    "    \n",
    "    lastFound = n+1\n",
    "    testVec[ddofs]=1 \n",
    "        \n",
    "    while True:\n",
    "        found = 0\n",
    "        tmp = lBasis @ testVec\n",
    "        # for i in range(n):\n",
    "        #     if abs(tmp[i])>1e-12:\n",
    "        #         #print('{}'.format(i))\n",
    "        #         found += 1\n",
    "        found = sum(abs(tmp)>1e-12)\n",
    "        if found > 0:\n",
    "            #print(found, lastFound)\n",
    "            assert(found < lastFound)\n",
    "            lastFound = found\n",
    "            lBasis = lBasis @ lBasis\n",
    "            print(\"multiply & repeat\")\n",
    "        else:\n",
    "            print(\"done\")\n",
    "            break\n",
    "    return lBasis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "28ecb3d8-7131-4d6c-aa09-0f13a5c28af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_active_constr(Constr):\n",
    "    #activeConstraints=[]\n",
    "    activeConstraints=[]\n",
    "    a=(Constr>1e-12).sum(axis=1).A.ravel(); b=(Constr<-1e-12).sum(axis=1).A.ravel()\n",
    "    activeConstraints=np.where(a+b>0)[0]\n",
    "    \n",
    "    signs=1.*((a<=1) | (a+b==0))-1.*((a>1)&(a+b>0))\n",
    "    #print(signs)\n",
    "    S=scipy.sparse.spdiags(signs,0,len(a),len(a))\n",
    "    \n",
    "    Constr[:] = S@Constr[:]\n",
    "    #assert np.all(((a[activeConstraints]==1) | (b[activeConstraints]==1))), 'error in constraint matrix.'\n",
    " \n",
    "\n",
    "#     for r in range(Constr.shape[0]):\n",
    "#         a = 0\n",
    "#         b = 0\n",
    "#         for ind in range(Constr.indptr[r], Constr.indptr[r+1]):\n",
    "#             if Constr.data[ind] > 1e-12:\n",
    "#                 a += 1\n",
    "#             if Constr.data[ind] < -1e-12:\n",
    "#                 b += 1\n",
    "#         if a+b>0:\n",
    "#             activeConstraints.append(r)\n",
    "#             #print(\"{}: {}, {}\".format(r,a,b))\n",
    "#             #if not a==1 or b==1: print(Constr[r,:])\n",
    "#             if not (a==1 or b==1): \n",
    "#                 print(a,b)\n",
    "#                 print(Constr[r,:])\n",
    "#             assert (a==1 or b==1), 'error in constraint matrix.'\n",
    "#             if a>1:\n",
    "#                 print( \"Re-sign\" )\n",
    "#                 Constr[r,:] *= -1\n",
    "                \n",
    "    return np.array(activeConstraints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8a056d02-3087-4851-971c-967d82a5fdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_basis(Constr, maxiter):\n",
    "    n=Constr.shape[1]\n",
    "    allLocalDofs=np.arange(n)\n",
    "    allderivedDofs={}\n",
    "    activeConstraints=np.arange(Constr.shape[0])\n",
    "    Basis=scipy.sparse.identity(n)\n",
    "    i=1\n",
    "    while len(activeConstraints)!=0:\n",
    "        if i>maxiter:\n",
    "            print(\"maxiter reached.\")\n",
    "            break\n",
    "        derivedDofs = elim_cycle(Constr, activeConstraints)  \n",
    "        #print(derivedDofs)\n",
    "        allderivedDofs.update(derivedDofs)\n",
    "        Basis = create_cycle_basis(Constr, derivedDofs, Basis)\n",
    "        #print(Basis.data)\n",
    "        Constr = Constr @ Basis    \n",
    "        activeConstraints = compute_active_constr(Constr)\n",
    "        i+=1\n",
    "        \n",
    "    #print(np.array(list(allderivedDofs.keys())))\n",
    "    nonderivedDofs=np.setdiff1d(allLocalDofs, np.array(list(allderivedDofs.keys())))\n",
    "    #print(nonderivedDofs)\n",
    "    return Basis[:,nonderivedDofs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0e812fef-5ee8-4d7b-ae1a-50cee9f97beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example 2D\n",
    "\n",
    "#setup initial discretization \n",
    "deg = 9\n",
    "N = 7\n",
    "kvs = [2*(bspline.make_knots(deg,0.0,1.0,N),),]\n",
    "\n",
    "# define geometry\n",
    "geos = [\n",
    "    geometry.unit_square()\n",
    "]\n",
    "\n",
    "patches = [(k, g) for k, g in zip(kvs,geos)]\n",
    "M = PatchMesh(patches)\n",
    "#M.refine(patches=1)\n",
    "\n",
    "#g = lambda x,y: x\n",
    "#g=u\n",
    "\n",
    "# dir_data = [\n",
    "#     (0, 'bottom', g), (0, 'left', g), (0, 'top', g),\n",
    "#     (1, 'right', g), (1, 'bottom', g), (1, 'top', g)\n",
    "# ]\n",
    "\n",
    "#M.split_patches()\n",
    "for i in range(90):\n",
    "    #print(i, (i+1)%2)\n",
    "    M.split_patches({i:(i+1)%2})\n",
    "\n",
    "# for i in range(100):\n",
    "#     number = math.floor(random.rand()*M.numpatches)\n",
    "#     direction = math.floor(random.rand()*2)\n",
    "#     #print(number, direction)\n",
    "    \n",
    "#     M.split_patches({number:direction})\n",
    "\n",
    "# for i in range(5):\n",
    "#     M.split_patches()\n",
    "    \n",
    "MP=Multipatch(M, automatch=True)\n",
    "#MP.patch_refine(patches={1:0})\n",
    "#MP.refine(patches={0})\n",
    "#MP.reset(automatch=True)\n",
    "#MP.finalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1a1bc202-84f8-4789-a966-7e8a4d80d59e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "M.draw(knots=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "29af68fa-39fb-46c1-88dc-fc62b997d59e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2864, 23296)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MP.Constr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fd057a19-f12c-47ae-b61a-40bf0767970c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiply & repeat\n",
      "done\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "Basis = compute_basis(MP.Constr.copy(), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3cb7c325-a9da-4276-9846-4b9e419e3b90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.7755575615628914e-16"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(MP.Constr@Basis).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81cc5e0c-f628-4a10-8dec-50eb044cf54a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

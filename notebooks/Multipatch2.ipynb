{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a79efc12-f80d-4be3-b107-4a7ec2e821af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import scipy\n",
    "import sys\n",
    "from scipy.sparse import coo_matrix, block_diag, identity, hstack\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from pyiga import bspline, vform, geometry, vis, solvers, utils\n",
    "from pyiga import assemble as Ass\n",
    "from patchmesh import *\n",
    "from patchmesh3D_2 import *\n",
    "import itertools as it\n",
    "#from multipatch import *\n",
    "\n",
    "numpy.set_printoptions(linewidth=100000)\n",
    "numpy.set_printoptions(precision=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1b22d4f2-ab7a-46d8-9e12-9894a3d0cca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rref(B, tol=1e-8, debug=False):\n",
    "    A = B.copy()\n",
    "    rows, cols = A.shape\n",
    "    r = 0\n",
    "    pivots_pos = []\n",
    "    row_exchanges = np.arange(rows)\n",
    "    for c in range(cols):\n",
    "        if debug: print(\"Now at row\", r, \"and col\", c, \"with matrix:\"); print (A)\n",
    "\n",
    "        ## Find the pivot row:\n",
    "        pivot = np.argmax (np.abs (A[r:rows,c])) + r\n",
    "        m = np.abs(A[pivot, c])\n",
    "        if debug: print(\"Found pivot\", m, \"in row\", pivot)\n",
    "        if m <= tol:\n",
    "            ## Skip column c, making sure the approximately zero terms are\n",
    "            ## actually zero.\n",
    "            if len(A[r:rows,c].shape)==1:\n",
    "                A[r:rows, c] = np.zeros(rows-r)\n",
    "            else:\n",
    "                A[r:rows, c] = np.zeros((rows-r,1))\n",
    "            if debug: print(\"All elements at and below (\", r, \",\", c, \") are zero.. moving on..\")\n",
    "        else:\n",
    "            ## keep track of bound variables\n",
    "            pivots_pos.append((r,c))\n",
    "\n",
    "            if pivot != r:\n",
    "                ## Swap current row and pivot row\n",
    "                A[[pivot, r], c:cols] = A[[r, pivot], c:cols]\n",
    "                row_exchanges[[pivot,r]] = row_exchanges[[r,pivot]]\n",
    "        \n",
    "                if debug: print(\"Swap row\", r, \"with row\", pivot, \"Now:\"); print(A)\n",
    "\n",
    "            ## Normalize pivot row\n",
    "            A[r, c:cols] = A[r, c:cols] / A[r, c];\n",
    "\n",
    "            ## Eliminate the current column\n",
    "            v = A[r, c:cols]\n",
    "            ## Above (before row r):\n",
    "            if r > 0:\n",
    "                ridx_above = np.arange(r)\n",
    "                A[ridx_above, c:cols] = A[ridx_above, c:cols] - np.outer(v, A[ridx_above, c]).T\n",
    "                if debug: print(\"Elimination above performed:\"); print(A)\n",
    "            ## Below (after row r):\n",
    "            if r < rows-1:\n",
    "                ridx_below = np.arange(r+1,rows)\n",
    "                A[ridx_below, c:cols] = A[ridx_below, c:cols] - np.outer(v, A[ridx_below, c]).T\n",
    "                if debug: print(\"Elimination below performed:\"); print(A)\n",
    "            r += 1\n",
    "        ## Check if done\n",
    "            if r == rows:\n",
    "                break;\n",
    "#         for r in reversed(range(rows)):\n",
    "#             if scipy.linalg.norm(A[r,:]) > tol:\n",
    "#                 break\n",
    "    return (A, pivots_pos, row_exchanges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cca4f286-0e9b-4014-8710-aec94a720fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basis_for_nullspace_of_dense_SVD(constr):\n",
    "    '''Derives a matrix representing a basis for the nullspace of a dense matrix using SVD'''\n",
    "    result = scipy.linalg.null_space(constr)\n",
    "    # Scaling: Largest entry should be 1\n",
    "    for i in range(result.shape[1]):\n",
    "        mx = result[:,i].max()\n",
    "        mn = result[:,i].min()\n",
    "        if mx > -mx:\n",
    "            result[:,i] /= mx\n",
    "        else:\n",
    "            result[:,i] /= mn\n",
    "    return result.transpose()\n",
    "\n",
    "def basis_for_nullspace_of_dense_LU(constr, tol=1e-8, idx=None):\n",
    "    '''Derives a matrix representing a basis for the nullspace of a dense matrix using LU'''\n",
    "    #P,L,U = scipy.linalg.lu(constr)\n",
    "    U, _, _ = rref(constr, tol=tol)\n",
    "    r,c = U.shape\n",
    "    #print(r,c)\n",
    "    # Remove (almost) empty rows\n",
    "    for i in range(r-1,-1,-1):\n",
    "        if (abs(U[i,:])<tol).all():\n",
    "            U = np.delete(U,i,0)\n",
    "    r,c = U.shape\n",
    "    #print(U)\n",
    "    # Swap cols if necessary\n",
    "    perm = np.arange(c)\n",
    "    for i in range(r):\n",
    "        if abs(U[i,i])<tol:\n",
    "            #mx = np.abs(U[i,i+1:]).max()\n",
    "            j = i\n",
    "            while abs(U[i,j]) < tol:\n",
    "                 j += 1\n",
    "#             j=i\n",
    "#             while abs(U[i,j])<tol:\n",
    "#                 j+=1\n",
    "            perm[i], perm[j] = perm[j], perm[i]\n",
    "            U[:,[i,j]] = U[:,[j,i]]\n",
    "    # Split matrix U and resolve linear system\n",
    "    #print(U)\n",
    "    U1 = U[:,:r]\n",
    "    U2 = U[:,r:]\n",
    "    sol = scipy.linalg.lu_solve((U1,np.arange(r)),U2)\n",
    "    # Setup result\n",
    "    result = np.zeros((c,c-r))\n",
    "    result[:r,:] = -sol\n",
    "    result[r:,:] = np.eye(c-r)    \n",
    "    # Apply perm\n",
    "    result2=result.copy()\n",
    "    result[list(perm)] = result2\n",
    "    # Scaling: Largest entry should be 1\n",
    "#     for i in range(result.shape[1]):\n",
    "#         mx = result[:,i].max()\n",
    "#         mn = result[:,i].min()\n",
    "#         if mx > -mx:\n",
    "#             result[:,i] /= mx\n",
    "#         else:\n",
    "#             result[:,i] /= mn\n",
    "    if idx is not None:\n",
    "        S=result.T[:,idx]\n",
    "        return scipy.linalg.solve(S,result.T)\n",
    "\n",
    "    return result.T\n",
    "\n",
    "def get_connected_components(constr):\n",
    "    '''Derives all connected components of the graph, where cols of matrix are nodes'''\n",
    "    assert isinstance(constr, scipy.sparse.csr_matrix)\n",
    "    (r, c) = constr.shape\n",
    "    \n",
    "    if not constr.has_sorted_indices:\n",
    "        constr.sort_indices()\n",
    "    \n",
    "    comps = np.arange(c)\n",
    "    for i in range(r):\n",
    "        smallest_index = c\n",
    "        for j in range(constr.indptr[i], constr.indptr[i+1]):\n",
    "            smallest_index = min(smallest_index, comps[constr.indices[j]])\n",
    "        for j in range(constr.indptr[i], constr.indptr[i+1]):\n",
    "            comps[constr.indices[j]] = smallest_index        \n",
    "    \n",
    "    for i in range(c):\n",
    "        if comps[comps[i]] < comps[i]:\n",
    "            comps[i] = comps[comps[i]]\n",
    "        \n",
    "    constr_list = {}\n",
    "    for i in range(r):\n",
    "        comp = comps[constr.indices[constr.indptr[i]]]\n",
    "        if comp not in constr_list:\n",
    "            constr_list[comp] = []         \n",
    "        constr_list[comp].append(i)\n",
    "        \n",
    "    comp_list = {}\n",
    "    coupled = np.zeros(c,'b')\n",
    "    for i in range(c):\n",
    "        comp = comps[i]\n",
    "        if comp != i or comp in constr_list.keys():\n",
    "            if not comp in comp_list:\n",
    "                comp_list[comp] = [comp]\n",
    "            if comp != i:\n",
    "                comp_list[comp].append(i)\n",
    "            coupled[i] = True\n",
    "    \n",
    "#     print(\"coupled     =\",coupled)\n",
    "#     print(\"comp_list   =\",comp_list)\n",
    "#     print(\"constr_list =\",constr_list)\n",
    "    \n",
    "    return coupled, comp_list, constr_list\n",
    "\n",
    "def basis_for_nullspace(constr, basis_for_nullspace_of_dense=basis_for_nullspace_of_dense_SVD, idx=None):\n",
    "    '''Derives a matrix representing a basis for the nullspace of a sparse matrix by first decomposing it into its connected components'''\n",
    "    assert isinstance(constr, scipy.sparse.csr_matrix)\n",
    "    (r, c) = constr.shape\n",
    "    \n",
    "    coupled, comp_list, constr_list = get_connected_components(constr)\n",
    "\n",
    "    mat = scipy.sparse.lil_matrix((c,c))\n",
    "    \n",
    "    # First, take the free dofs as they are\n",
    "    row = 0\n",
    "    for i in range(c):\n",
    "        if not coupled[i]:\n",
    "            mat[row,i] = 1\n",
    "            row += 1\n",
    "\n",
    "    # TODO: Secondly, take the dofs with one-to-one mapping\n",
    "    \n",
    "    # Finally, take the other dofs\n",
    "    for i in comp_list.keys():\n",
    "        comp_item = comp_list[i]\n",
    "        constr_item = constr_list[i]\n",
    "        local_matrix = (constr[constr_item,:][:,comp_item]).A\n",
    "        if idx is not None:\n",
    "            loc_idx = np.array([i for i in range(len(comp_item)) if idx[comp_item[i]]==1])\n",
    "        else:\n",
    "            loc_idx=None\n",
    "        local_basis  = basis_for_nullspace_of_dense(local_matrix, idx=loc_idx)\n",
    "        #print( \"local_matrix:\\n\", local_matrix )\n",
    "        #print( \"local_basis :\\n\", local_basis  )\n",
    "        lb_rows, lb_cols = local_basis.shape\n",
    "        for i0 in range(lb_rows):\n",
    "            for j0 in range(lb_cols):\n",
    "                mat[row,comp_item[j0]] = local_basis[i0,j0]\n",
    "            row += 1\n",
    "\n",
    "    mat.resize(row,c)\n",
    "    return mat.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c3986e24-4539-418c-93b3-42e7f62283b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PoissonEstimator(MP,f,uh):\n",
    "    n = MP.mesh.numpatches\n",
    "    indicator = np.zeros(n)\n",
    "    params = {'f': f}\n",
    "    \n",
    "    uh_per_patch = dict()\n",
    "    \n",
    "    #residual contribution\n",
    "    for p, ((kvs, geo), _) in enumerate(MP.mesh.patches):\n",
    "        \n",
    "        h = np.linalg.norm([b-a for a,b in geo.bounding_box()])\n",
    "        \n",
    "        N = tuple(kv.numdofs for kv in kvs)\n",
    "        uh_per_patch[p] = (MP.global_to_patch(p) @ uh).reshape(N)   #cache Spline Function on patch p\n",
    "        \n",
    "        params['geo'] = geo\n",
    "        params['uh_func'] = geometry.BSplineFunc(kvs, uh_per_patch[p])\n",
    "        \n",
    "        kvs0 = tuple([bspline.KnotVector(kv.mesh, 0) for kv in kvs])\n",
    "        indicator[p] = h**2 * np.sum(Ass.assemble('(f + div(grad(uh_func)))**2 * v * dx', kvs0, params))\n",
    "        \n",
    "    params = dict()\n",
    "    \n",
    "    #flux contribution\n",
    "    for i,((p1,b1,_), (p2,b2,_), _, flip) in enumerate(MP.intfs):\n",
    "        #print(p1, p2, flip)\n",
    "        \n",
    "        ((kvs1, geo1), _), ((kvs2, geo2), _) = MP.mesh.patches[p1], MP.mesh.patches[p2]\n",
    "        bdspec1, bdspec2 = Ass.int_to_bdspec(b1), Ass.int_to_bdspec(b2)\n",
    "        \n",
    "        bkv1, bkv2 = Ass.boundary_kv(kvs1, bdspec1), Ass.boundary_kv(kvs2, bdspec2)\n",
    "\n",
    "        geo = geo2.boundary(bdspec2)\n",
    "        params['geo'] = geo\n",
    "        \n",
    "        kv0 = tuple([bspline.KnotVector(kv.mesh, 0) for kv in bkv2])\n",
    "        h = np.sum(Ass.assemble('v * ds', kv0, params))\n",
    "        \n",
    "        params['uh_grad1'] = geometry.BSplineFunc(kvs1, uh_per_patch[p1]).transformed_jacobian(geo1).boundary(bdspec1, flip=flip) #physical gradient of uh on patch 1 (flipped if needed)\n",
    "        params['uh_grad2'] = geometry.BSplineFunc(kvs2, uh_per_patch[p2]).transformed_jacobian(geo2).boundary(bdspec2)            #physical gradient of uh on patch 2\n",
    "        #params['uh1'] = geometry.BSplineFunc(kvs1, uh_per_patch[p1]).boundary(bdspec1,flip=flip)\n",
    "        #params['uh2'] = geometry.BSplineFunc(kvs2, uh_per_patch[p2]).boundary(bdspec2)\n",
    "        normalflux_jump = np.sum(Ass.assemble('(inner(uh_grad1 - uh_grad2, n) )**2 * v * ds', kv0 ,params))\n",
    "        #print(normalflux_jump)\n",
    "\n",
    "        indicator[p1] += 0.5 * h * normalflux_jump\n",
    "        indicator[p2] += 0.5 * h * normalflux_jump\n",
    "    \n",
    "    return np.sqrt(indicator)\n",
    "\n",
    "def check_coupling(MP, u_):\n",
    "    u_pp = dict()\n",
    "\n",
    "    for i,((p1,b1,_), (p2,b2,_), flip) in enumerate(MP.intfs):\n",
    "        \n",
    "        ((kvs1,_),_), ((kvs2,_),_) = MP.mesh.patches[p1], MP.mesh.patches[p2]\n",
    "        bdspec1, bdspec2 = int_to_bdspec(b1), int_to_bdspec(b2)\n",
    "        (kv1), (kv2) = boundary_kv(kvs1, bdspec1), boundary_kv(kvs2, bdspec2, flip=flip)\n",
    "        dofs1, dofs2 = Ass.boundary_dofs(kvs1, bdspec1, ravel=True), Ass.boundary_dofs(kvs2, bdspec2, ravel=True, flip=flip)\n",
    "        \n",
    "        if p1 not in u_pp:\n",
    "            u_pp[p1]=MP.global_to_patch(p1) @ u_\n",
    "        if p2 not in u_pp:\n",
    "            u_pp[p2]=MP.global_to_patch(p2) @ u_\n",
    "          \n",
    "        P = bspline.prolongation(kv1, kv2)\n",
    "        u1, u2 = u_pp[p1][dofs1], u_pp[p2][dofs2]\n",
    "        r=norm(u2 - P @ u1)\n",
    "        \n",
    "        if r>1e-8:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "class Multipatch:\n",
    "    \"\"\"Represents a multipatch structure, consisting of a number of patches\n",
    "    together with their discretizations and the information about shared dofs\n",
    "    between patches. Nonconforming patches (both geometrically and knotwise non conforming) are allowed as long as there exists \n",
    "    a hierarchy between the interface knots\n",
    "\n",
    "    Args:\n",
    "        pm: A :class:`PatchMesh` instance representing the patches \n",
    "            via their discretization and their geometry function \n",
    "            as well as the generated mesh between the patches (vertices, interfaces).\n",
    "            \n",
    "        b_data: A dictionary of the form {'D':dir_data, 'N':neu_data, 'R': robin_data}\n",
    "            dir_data: A list of triples (patch, bdspec, dir_func) prescribing the function `dir_func` to boundary dofs of `patch` on side `bdspec`.\n",
    "            neu_data: A list of triples (patch, bdspec, neu_func) in order to assemble natural boundary conditions for boundary dofs of `patch` on side `bdspec`.\n",
    "            robin_data: A list of triples (patch, bd_spec, (gamma, robin_func))\n",
    "        \n",
    "        automatch (bool): if True, attempt to automatically apply the interface information from the PatchMesh object to couple the patches.\n",
    "            If False, the user has to manually join the patches by calling\n",
    "            :meth:`join_boundaries` as often as needed, followed by\n",
    "            :meth:`finalize`.\n",
    "    \"\"\"\n",
    "    def __init__(self, pm, automatch=False, dim=2):\n",
    "        \"\"\"Initialize a multipatch structure.\"\"\"\n",
    "        # underlying PatchMesh object describing the geometry\n",
    "        self.mesh = pm\n",
    "        # enforced regularity across patch interfaces\n",
    "        #self.k = k\n",
    "        self.dim = dim \n",
    "            \n",
    "        # number of tensor product dofs per patch\n",
    "        self.n = [tuple([kv.numdofs for kv in kvs]) for ((kvs,_),_) in self.mesh.patches]\n",
    "        self.N = [np.prod(n) for n in self.n]\n",
    "        # offset to the dofs of the i-th patch\n",
    "        self.N_ofs = np.concatenate(([0], np.cumsum(self.N)))\n",
    "        # per patch, a dict of shared indices\n",
    "        self.shared_pp = dict(zip([p for p in range(self.mesh.numpatches)],self.mesh.numpatches*[set(),]))\n",
    "        # a list of interfaces (patch1, boundary dofs1, patch2, boundary dofs2)\n",
    "        self.intfs = set()\n",
    "        self.Constr=scipy.sparse.csr_matrix((0,self.N_ofs[-1]))\n",
    "        self.dof_class={dof:0 for dof in np.arange(self.N_ofs[-1])}\n",
    "\n",
    "        if automatch:\n",
    "            interfaces = self.mesh.interfaces.copy()\n",
    "            \n",
    "            for ((p1,bd1,s1),((p2,bd2,s2),flip)) in interfaces.items():\n",
    "                if ((p2,bd2,s2),(p1,bd1,s1),flip) not in self.intfs:\n",
    "                    self.intfs.add(((p1,bd1,s1),(p2,bd2,s2),flip))\n",
    "                \n",
    "            #print(self.intfs)\n",
    "            for ((p1,bd1,s1),(p2,bd2,s2), flip) in self.intfs:\n",
    "                bdspec1 = (Ass.int_to_bdspec(bd1),)\n",
    "                bdspec2 = (Ass.int_to_bdspec(bd2),)\n",
    "                self.join_boundaries(p1, bdspec1, s1 , p2, bdspec2, s2, flip)\n",
    "            #self.finalize()\n",
    "\n",
    "    @property\n",
    "    def numpatches(self):\n",
    "        \"\"\"Number of patches in the multipatch structure.\"\"\"\n",
    "        return len(self.mesh.patches)\n",
    "\n",
    "    @property\n",
    "    def numdofs(self):\n",
    "        \"\"\"Number of dofs after eliminating shared dofs.\n",
    "\n",
    "        May only be called after :func:`finalize`.\n",
    "        \"\"\"\n",
    "        return self.Basis.shape[0]\n",
    "    \n",
    "    @property\n",
    "    def numloc_dofs(self):\n",
    "        return self.N_ofs[-1]\n",
    "    \n",
    "    def reset(self, automatch = False):\n",
    "        self.__init__(pm=self.mesh, b_data=self.b_data, dim=self.dim, automatch=automatch)\n",
    "\n",
    "    def join_boundaries(self, p1, bdspec1, s1, p2, bdspec2, s2, flip=None):\n",
    "        \"\"\"Join the dofs lying along boundary `bdspec1` of patch `p1` with\n",
    "        those lying along boundary `bdspec2` of patch `p2`. \n",
    "\n",
    "        See :func:`compute_dirichlet_bc` for the format of the boundary\n",
    "        specification.\n",
    "\n",
    "        If `flip` is given, it should be a sequence of booleans indicating for\n",
    "        each coordinate axis of the boundary if the coordinates of `p2` have to\n",
    "        be flipped along that axis.\n",
    "        \"\"\"\n",
    "        \n",
    "        kvs1, kvs2 = self.mesh.patches[p1][0][0], self.mesh.patches[p2][0][0]\n",
    "        if flip is None:\n",
    "            flip=(self.dim-1)*(False,)\n",
    "        \n",
    "        bkv1 = Ass.boundary_kv(kvs1, bdspec1)\n",
    "        bkv2 = Ass.boundary_kv(kvs2, bdspec2, flip=flip) \n",
    "        \n",
    "        #retrieve local dofs for each patch on the boundary\n",
    "        dofs1 = Ass.boundary_dofs(self.mesh.patches[p1][0][0], bdspec1, ravel=True)\n",
    "        dofs2 = Ass.boundary_dofs(self.mesh.patches[p2][0][0], bdspec2, ravel=True, flip=flip)\n",
    "                \n",
    "        #check for hierarchy of the boundary knot vectors. currently only supports knot vectors with equal degree.\n",
    "        if all([bspline.is_sub_space(kv1,kv2) for kv1, kv2 in zip(bkv1,bkv2)]):\n",
    "            pass\n",
    "        elif all([bspline.is_sub_space(kv2,kv1) for kv1, kv2 in zip(bkv1,bkv2)]):          \n",
    "            p1, p2 = p2, p1\n",
    "            bdspec1, bdspec2 = bdspec2, bdspec1\n",
    "            bkv1, bkv2 = bkv2, bkv1\n",
    "            dofs1, dofs2 = dofs2, dofs1\n",
    "        else:\n",
    "            print('interface coupling not possible')\n",
    "            \n",
    "        for dof in dofs1:\n",
    "            if self.dof_class[dof + self.N_ofs[p1]]==0:\n",
    "                self.dof_class[dof + self.N_ofs[p1]]=1\n",
    "        for dof in dofs2:\n",
    "            self.dof_class[dof + self.N_ofs[p2]]=2\n",
    "            \n",
    "        self.shared_pp[p1]=self.shared_pp[p1] | set(dofs1)\n",
    "        self.shared_pp[p2]=self.shared_pp[p2] | set(dofs2)\n",
    "            \n",
    "        #Prolongation operator  \n",
    "        P = -scipy.sparse.coo_matrix(bspline.prolongation_tp(bkv1,bkv2))   #TODO: make paramater to generate prolongation matrix as coo_matrix directly?\n",
    "        #construct constraints for this interface\n",
    "        data = np.concatenate([P.data, np.ones(len(dofs2))])\n",
    "        I = np.concatenate([P.row, np.arange(len(dofs2))])\n",
    "        J = np.concatenate([dofs1[P.col] + self.N_ofs[p1],dofs2 + self.N_ofs[p2]])\n",
    "        \n",
    "        self.Constr = scipy.sparse.vstack([self.Constr,scipy.sparse.coo_matrix((data,(I,J)),(len(dofs2), self.numloc_dofs)).tocsr()])\n",
    "        \n",
    "           \n",
    "    def finalize(self):\n",
    "        \"\"\"After all shared dofs have been declared using\n",
    "        :meth:`join_boundaries` or :meth:`join_dofs`, call this function to set\n",
    "        up the internal data structures.\n",
    "        \"\"\"\n",
    "        num_shared = [len(self.shared_pp[p]) for p in range(self.numpatches)]\n",
    "        # number of local dofs per patch\n",
    "        self.M = [n - s for (n, s) in zip(self.N, num_shared)]\n",
    "        # local-to-global offset per patch\n",
    "        self.M_ofs = np.concatenate(([0], np.cumsum(self.M)))\n",
    "        self.Basis = basis_for_nullspace(self.Constr, basis_for_nullspace_of_dense_LU, idx=self.dof_class)\n",
    "        #self.sanity_check()   \n",
    "\n",
    "    def assemble_system(self, problem, rhs, args=None, bfuns=None,\n",
    "            symmetric=False, format='csr', layout='blocked', **kwargs):\n",
    "        \"\"\"Assemble both the system matrix and the right-hand side vector\n",
    "        for a variational problem over the multipatch geometry.\n",
    "\n",
    "        Here `problem` represents a bilinear form and `rhs` a linear functional.\n",
    "        See :func:`assemble` for the precise meaning of the arguments.\n",
    "\n",
    "        Returns:\n",
    "            A pair `(A, b)` consisting of the sparse system matrix and the\n",
    "            right-hand side vector.\n",
    "        \"\"\"\n",
    "        n = self.numdofs\n",
    "        X=MP.Basis\n",
    "        \n",
    "        A = []\n",
    "        b = []\n",
    "        if args is None:\n",
    "            args = dict()\n",
    "        for p in range(self.numpatches):\n",
    "            kvs, geo = self.mesh.patches[p][0]\n",
    "            args.update(geo=geo)\n",
    "            # TODO: vector-valued problems\n",
    "            A.append(Ass.assemble(problem, kvs, args=args, bfuns=bfuns,\n",
    "                    symmetric=symmetric, format=format, layout=layout,\n",
    "                    **kwargs))\n",
    "    \n",
    "            b.append(Ass.assemble(rhs, kvs, args=args, bfuns=bfuns,\n",
    "                    symmetric=symmetric, format=format, layout=layout,\n",
    "                    **kwargs).ravel())\n",
    "        A = X@scipy.sparse.block_diag(A)@X.T\n",
    "        b = X@np.concatenate(b)\n",
    "            \n",
    "        return A, b\n",
    "    \n",
    "    def assemble_surface(self, problem, arity=1, boundary_idx=0, args=None, bfuns=None,\n",
    "            symmetric=False, format='csr', layout='blocked', **kwargs):\n",
    "        X = MP.Basis\n",
    "        if args is None:\n",
    "            args = dict()\n",
    "        if arity==2:\n",
    "            I, J, data = [], [], []\n",
    "            for (p,b) in self.mesh.outer_boundaries[boundary_idx]:\n",
    "                kvs, geo = self.mesh.patches[p][0]\n",
    "                bdspec=[(b//2,b%2)]\n",
    "                bdofs = Ass.boundary_dofs(kvs, bdspec, ravel=True) + self.N_ofs[p]\n",
    "                args.update(geo = geo)\n",
    "                \n",
    "                R = Ass.assemble(problem, kvs, args=args, bfuns=bfuns,\n",
    "                        symmetric=symmetric, format='coo', layout=layout,\n",
    "                        **kwargs, boundary=bdspec)\n",
    "                \n",
    "                I_p ,J_p = R.row, R.col\n",
    "                I.append(bdofs[I_p]), J.append(bdofs[J_p]), data.append(R.data)\n",
    "                \n",
    "            I, J, data = np.concatenate(I), np.concatenate(J), np.concatenate(data)\n",
    "            R = scipy.sparse.coo_matrix((data, (I, J)), 2*(self.numloc_dofs,))\n",
    "            return X @ scipy.sparse.csr_matrix(R) @ X.T\n",
    "        else:\n",
    "            N=np.zeros(self.numloc_dofs)\n",
    "            for (p,b) in self.mesh.outer_boundaries[boundary_idx]:\n",
    "                kvs, geo = self.mesh.patches[p][0]\n",
    "                bdspec=[(b//2,b%2)]\n",
    "                bdofs = Ass.boundary_dofs(kvs, bdspec, ravel=True) + self.N_ofs[p]\n",
    "                args.update(geo = geo)\n",
    "    \n",
    "                vals=Ass.assemble(problem, kvs, args=args, bfuns=bfuns,\n",
    "                        symmetric=symmetric, format=format, layout=layout,\n",
    "                        **kwargs, boundary=bdspec).ravel()\n",
    "                N[bdofs] += vals \n",
    "            \n",
    "            return X @ N\n",
    "            \n",
    "    \n",
    "#     def assemble_boundary(self, problem, boundary_idx = None, args=None, bfuns=None,\n",
    "#             symmetric=False, format='csr', layout='blocked', **kwargs):\n",
    "        \n",
    "    \n",
    "#     def C1_coupling(self, p1, bdspec1, p2, bdspec2, flip=None):\n",
    "        \n",
    "#         (ax1, sd1), (ax2, sd2) = bdspec1, bdspec2\n",
    "#         ((kvs1, geo1),_), ((kvs2, geo2),_) = self.mesh.patches[p1], self.mesh.patches[p2]\n",
    "#         sup1, sup2 = geo1.support, geo2.support\n",
    "#         dim=len(kvs1)\n",
    "#         if flip is None:\n",
    "#             flip=(dim-1)*(False,)\n",
    " \n",
    "#         bkv1, bkv2 = Ass.boundary_kv(kvs1, bdspec1), Ass.boundary_kv(kvs2, bdspec2)\n",
    "#         dofs1, dofs2 = Ass.boundary_dofs(kvs1, bdspec1, ravel = True, k=1), Ass.boundary_dofs(kvs2, bdspec2, ravel = True, flip=flip, k=1)\n",
    "#         G = tuple(kv.greville() for kv in kvs2)\n",
    "#         G2 = G[:ax2] + (np.array([sup2[ax2][0] if sd2==0 else sup2[ax2][-1]]),) + G[ax2+1:]\n",
    "#         G1 = G[:ax2] + G[ax2+1:]\n",
    "#         G1 = G1[:ax1] + (np.array([sup1[ax1][0] if sd1==0 else sup1[ax1][-1]]),) + G1[ax1:] #still need to add flip\n",
    "\n",
    "#         M=tuple(len(g) for g in G2)\n",
    "#         m=np.prod(M)\n",
    "#         n1,n2=len(dofs1), len(dofs2)\n",
    "        \n",
    "#         C1, D1 = bspline.collocation_derivs_tp(kvs1, G1, derivs=1)\n",
    "#         C2, D2 = bspline.collocation_derivs_tp(kvs2, G2, derivs=1)\n",
    "    \n",
    "#         C1, C2 = C1[0].tocsr()[:,dofs1], C2[0].tocsr()[:,dofs2]\n",
    "#         for i in range(dim):\n",
    "#             D1[i], D2[i] = D1[i].tocsr()[:,dofs1], D2[i].tocsr()[:,dofs2]\n",
    "#         N2=geo2.boundary(bdspec2).grid_outer_normal(G2[:ax2]+G2[ax2+1:]).reshape(m,dim)\n",
    "\n",
    "#         J1=geo1.grid_jacobian(G1).reshape(m,dim,dim)\n",
    "#         J2=geo2.grid_jacobian(G2).reshape(m,dim,dim)\n",
    "        \n",
    "#         invJ1=np.array([inv(jac) for jac in J1[:]])\n",
    "#         invJ2=np.array([inv(jac) for jac in J2[:]])\n",
    "\n",
    "#         NC1=scipy.sparse.csr_matrix((m, n1))\n",
    "#         for i in range(dim):\n",
    "#             NC1_ = scipy.sparse.csr_matrix((m, n1))\n",
    "#             for j in range(dim):\n",
    "#                 NC1_ += scipy.sparse.spdiags(invJ1[:,i,j], 0, m, m)*D1[dim-1-j]\n",
    "#             NC1 += scipy.sparse.spdiags(N2[:,i], 0, m, m)*NC1_\n",
    "            \n",
    "#         NC2=scipy.sparse.csr_matrix((m, n2))\n",
    "#         for i in range(dim):\n",
    "#             NC2_ = scipy.sparse.csr_matrix((m, n2))\n",
    "#             for j in range(dim):\n",
    "#                 NC2_ += scipy.sparse.spdiags(invJ2[:,i,j], 0, m, m)*D2[dim-1-j]\n",
    "#             NC2 += scipy.sparse.spdiags(N2[:,i], 0, m, m)*NC2_\n",
    "            \n",
    "#         A = scipy.sparse.vstack([C1, NC1])\n",
    "#         B = scipy.sparse.vstack([C2, NC2])\n",
    "#         P = scipy.sparse.linalg.spsolve(B,A.A)\n",
    "#         # prune matrix\n",
    "#         P[np.abs(P) < 1e-15] = 0.0\n",
    "#         return scipy.sparse.csr_matrix(P) \n",
    "        \n",
    "    def L2Projection(self, u):\n",
    "        M, rhs, _, _, _ = self.assemble_system(vform.mass_vf(2), vform.L2functional_vf(2, physical=True), f=u)\n",
    "        u_ = solvers.make_solver(M, spd=True).dot(rhs)\n",
    "        return u_\n",
    "    \n",
    "    def refine(self, patches=None, mult=1, return_prol=False):\n",
    "        if isinstance(patches, dict):\n",
    "            assert max(patches.keys())<self.numpatches and min(patches.keys())>=0, \"patch index out of bounds.\"\n",
    "            patches = patches.keys()\n",
    "        elif isinstance(patches, (list, set, np.ndarray)):\n",
    "            assert max(patches)<self.numpatches and min(patches)>=0, \"patch index out of bounds.\"\n",
    "        elif patches==None:\n",
    "            patches = np.arange(self.numpatches)\n",
    "        elif np.isscalar(patches):\n",
    "            patches=(patches,)\n",
    "        else:\n",
    "            assert 0, \"unknown input type\"\n",
    "        if return_prol:\n",
    "            n=self.numdofs\n",
    "            old_kvs=[kvs for (kvs,_),_ in self.mesh.patches]\n",
    "            old_global_to_patch = [self.global_to_patch(p) for p in range(self.numpatches)]\n",
    "            \n",
    "        self.mesh.refine(patches, mult=mult)\n",
    "        self.reset(automatch=True)\n",
    "        #MP = Multipatch(self.mesh, automatch=True, k=self.k)\n",
    "        \n",
    "        if return_prol:\n",
    "            m = self.numdofs\n",
    "            P = scipy.sparse.csr_matrix((m, n))\n",
    "            \n",
    "            for p in range(self.numpatches):\n",
    "                if p in patches:\n",
    "                    kvs=old_kvs[p]\n",
    "                    new_kvs=MP.mesh.patches[p][0][0]\n",
    "                    C = bspline.prolongation_tp(kvs, new_kvs)\n",
    "                else:\n",
    "                    C = scipy.sparse.identity(self.N[p])\n",
    "\n",
    "                P += MP.patch_to_global(p) @ C @ old_global_to_patch[p]\n",
    "            factors = [1/sum([sum(dof[p][1]) for p in dof]) for dof in MP.shared_dofs]\n",
    "            P[MP.M_ofs[-1]:] = scipy.sparse.spdiags(factors, 0, len(factors), len(factors)) @ P[MP.M_ofs[-1]:]\n",
    "            return P\n",
    "        \n",
    "    def patch_refine(self, patches=None, mult=1, return_prol = False):\n",
    "        \"\"\"Refines the Mesh by splitting patches\n",
    "        \n",
    "        The dictionary `patches` specifies which patches (dict keys) are to be split \n",
    "        and how to split them (dict values: 0 to dim-1 or None)\n",
    "        \n",
    "        The `return_prol` keyword enables also the generation of a prolongation matrix from one mesh to the split mesh.\n",
    "        \n",
    "        Returns:\n",
    "            A new :class:`Multipatch` object `MP`\n",
    "            A sparse matrix `P` suitable for prolongation.\n",
    "        \"\"\"\n",
    "        if isinstance(patches, dict):\n",
    "            assert max(patches.keys())<self.numpatches and min(patches.keys())>=0, \"patch index out of bounds.\"\n",
    "        elif isinstance(patches,int):\n",
    "            #assert patches >=0 and patches < self.dim, \"dimension error.\"\n",
    "            patches = {p:patches for p in range(self.numpatches)}\n",
    "        elif isinstance(patches, (list, set, np.ndarray)):\n",
    "            assert max(patches)<self.numpatches and min(patches)>=0, \"patch index out of bounds.\"\n",
    "            patches = {p:None for p in patches}\n",
    "        elif patches==None:\n",
    "            patches = {p:None for p in range(self.numpatches)}\n",
    "        else:\n",
    "            assert 0, \"unknown input type\"\n",
    "        \n",
    "        #n=self.numdofs\n",
    "        N=self.numpatches\n",
    "\n",
    "        #M = copy.deepcopy(self.mesh)\n",
    "        #old_kvs = [kvs for (kvs,_),_ in self.mesh.patches]\n",
    "       # old_global_to_patch = [self.global_to_patch(p) for p in range(self.numpatches)]\n",
    "        \n",
    "        new_patches = dict()\n",
    "        new_kvs_ = dict()\n",
    "        for p in patches.keys():\n",
    "            self.split_boundary_data(p, self.numpatches, axis=patches[p])\n",
    "            new_patches[p], new_kvs_[p] = self.mesh.split_patch(p, axis=patches[p], mult=mult)\n",
    "        \n",
    "        #MP = Multipatch(self.mesh, automatch=True, k=self.k)\n",
    "        self.reset(automatch=True)\n",
    "        #m = self.numdofs\n",
    "        \n",
    "        if return_prol:\n",
    "            P = scipy.sparse.csr_matrix((m, n))\n",
    "            for p in range(N):\n",
    "                kvs=old_kvs[p]\n",
    "                if p in new_patches:\n",
    "                    new_kvs = new_kvs_[p]\n",
    "                    S = scipy.sparse.csr_matrix((m,bspline.numdofs(new_kvs)))\n",
    "                    C =  bspline.prolongation_tp(kvs, new_kvs)\n",
    "                    \n",
    "                    for i, new_p in enumerate(new_patches[p]):\n",
    "                    \n",
    "                        val = np.ones(self.N[new_p])\n",
    "                        I = np.arange(self.N[new_p])\n",
    "                        \n",
    "                        if patches[p]==0:\n",
    "                            bdspec = (0,i)\n",
    "                            k = self.mesh.patches[new_p][0][0][0].numdofs\n",
    "                            J = np.sort(Ass.boundary_dofs(new_kvs,bdspec,ravel=True,k=k-1))\n",
    "                        elif patches[p]==1:\n",
    "                            bdspec = (1,i)\n",
    "                            k = self.mesh.patches[new_p][0][0][1].numdofs\n",
    "                            J = np.sort(Ass.boundary_dofs(new_kvs,bdspec,ravel=True,k=k-1))\n",
    "                        else:\n",
    "                            cspec=(i//2,i%2)\n",
    "                            k0=self.mesh.patches[new_p][0][0][0].numdofs\n",
    "                            k1=self.mesh.patches[new_p][0][0][1].numdofs\n",
    "                            J = np.sort(Ass.boundary_dofs(new_kvs,cspec,k=[k0-1,k1-1], ravel=True))\n",
    "               \n",
    "                        R = scipy.sparse.coo_matrix((val,(I,J)),shape=(self.N[new_p],bspline.numdofs(new_kvs)))\n",
    "                        S += self.patch_to_global(new_p) @ R\n",
    "                else:\n",
    "                    S=self.patch_to_global(p)\n",
    "                    C=scipy.sparse.identity(self.N[p])\n",
    "                \n",
    "                P += S @ C @ old_global_to_patch[p]\n",
    "                \n",
    "            factors = [1/sum([sum(dof[p][1]) for p in dof]) for dof in self.shared_dofs]\n",
    "            P[self.M_ofs[-1]:] = scipy.sparse.spdiags(factors, 0, len(factors), len(factors)) @ P[self.M_ofs[-1]:]\n",
    "            return P\n",
    "        \n",
    "#     def split_boundary_data(self, p, n, axis = None):\n",
    "#         \"\"\"Splits the boundary information of a patch `p`.\n",
    "    \n",
    "#         Args:\n",
    "#             p: patch to be split\n",
    "#             n: total number of patches\n",
    "#             dir_data: information of the Dirichlet condition over the whole PatchMesh structure\n",
    "            \n",
    "#         Returns:\n",
    "#             Modified list `dir_data` with split patches.\n",
    "#         \"\"\"\n",
    "#         if axis==None:\n",
    "#             axis=tuple(range(self.dim))\n",
    "#         axis=np.unique(axis)\n",
    "#         if len(axis)==1: axis=axis[0]\n",
    "#         for s in self.b_data.keys():\n",
    "            \n",
    "#             b_data_p = [(patch , bd, g) for (patch, bd, g) in self.b_data[s] if patch == p]\n",
    "            \n",
    "#             if b_data_p:\n",
    "#                 if not np.isscalar(axis):\n",
    "#                     for k,ax in enumerate(axis[::-1]):\n",
    "#                         self.split_boundary_data(p, n+2**k-1, axis=ax)\n",
    "#                         for i in range(2**k-1):\n",
    "#                             self.split_boundary_data(n+i, n+2**k+i, axis=ax)\n",
    "#                 else:\n",
    "#                     for (patch, bd, g) in b_data_p:\n",
    "#                         if self.dim==3:\n",
    "#                             if axis == self.dim - 3:\n",
    "#                                 if bd == 'back':\n",
    "#                                     self.b_data[s].remove((patch, bd, g))\n",
    "#                                     self.b_data[s].append((n, bd, g))\n",
    "#                                 if bd == 'left' or bd == 'right' or bd == 'bottom' or bd=='top':\n",
    "#                                     self.b_data[s].append((n, bd, g))\n",
    "#                         if axis == self.dim - 2:\n",
    "#                             if bd == 'top':\n",
    "#                                 self.b_data[s].remove((patch, bd, g))\n",
    "#                                 self.b_data[s].append((n, bd, g))\n",
    "#                             if bd == 'left' or bd == 'right':\n",
    "#                                 self.b_data[s].append((n, bd, g))\n",
    "#                             if self.dim == 3:\n",
    "#                                 if bd == 'front' or bd == 'back':\n",
    "#                                     self.b_data[s].append((n, bd, g)) \n",
    "#                         if axis == self.dim - 1:\n",
    "#                             if bd == 'right':\n",
    "#                                 self.b_data[s].remove((patch, bd, g))\n",
    "#                                 self.b_data[s].append((n, bd, g))   \n",
    "#                             if bd == 'bottom' or bd == 'top':\n",
    "#                                 self.b_data[s].append((n, bd, g))\n",
    "#                             if self.dim == 3:\n",
    "#                                 if bd == 'front' or bd == 'back':\n",
    "#                                     self.b_data[s].append((n, bd, g)) \n",
    "\n",
    "    def compute_dirichlet_bcs(self):\n",
    "        \"\"\"Performs the same operation as the global function\n",
    "        :func:`compute_dirichlet_bcs`, but for a multipatch problem.\n",
    "\n",
    "        The sequence `dir_data` should contain triples of the form `(patch,\n",
    "        bdspec, dir_func)`.\n",
    "\n",
    "        Returns:\n",
    "            A pair `(indices, values)` suitable for passing to\n",
    "            :class:`RestrictedLinearSystem`.\n",
    "        \"\"\"\n",
    "        bcs = []\n",
    "        p2g = dict()        # cache the patch-to-global indices for efficiency\n",
    "        for (p, bdspec, g) in self.b_data['D']:\n",
    "            (kvs, geo), _ = self.mesh.patches[p]\n",
    "            bc = Ass.compute_dirichlet_bc(kvs, geo, bdspec, g)\n",
    "            if p not in p2g:\n",
    "                p2g[p] = self.patch_to_global_idx(p)\n",
    "            idx = p2g[p]    # maps local dofs to global dofs\n",
    "            bcs.append((*idx[bc[0],0].toarray().T, bc[1]))\n",
    "        return Ass.combine_bcs(bcs)\n",
    "    \n",
    "    def sanity_check(self):\n",
    "        for p in range(self.numpatches):\n",
    "            assert all([np.isclose(sum(coeffs),1.0) for _,coeffs in self.shared_per_patch[p].values()]), 'coupling of dofs is flawed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ed05e3bc-3590-429c-bcba-ad39081c2367",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example 1\n",
    "\n",
    "#setup initial discretization \n",
    "deg = 1\n",
    "N=1\n",
    "kvs = 2*[2*(bspline.make_knots(deg,0.0,1.0,N),),]\n",
    "\n",
    "# define geometry\n",
    "geos = [\n",
    "    geometry.unit_square(),\n",
    "    geometry.unit_square().translate((1,0))\n",
    "]\n",
    "\n",
    "patches = [(k, g) for k, g in zip(kvs,geos)]\n",
    "M = PatchMesh(patches)\n",
    "#M.refine(patches=1)\n",
    "\n",
    "g = lambda x,y: x\n",
    "#g=u\n",
    "\n",
    "dir_data = [\n",
    "    (0, 'bottom', g), (0, 'left', g), (0, 'top', g),\n",
    "    (1, 'right', g), (1, 'bottom', g), (1, 'top', g)\n",
    "]\n",
    "\n",
    "for i in range(5):\n",
    "    M.split_patches({i+1:i%2})\n",
    "MP=Multipatch(M, automatch=True)\n",
    "#MP.patch_refine(patches={1:0})\n",
    "#MP.refine(patches={0})\n",
    "#MP.reset(automatch=True)\n",
    "MP.finalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "acd585a6-9f51-432e-8d53-41776a91fb89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "M.draw(patch_idx=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e0693456-de1b-4088-9bef-42371c88861d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<22x11 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 0 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MP.Constr@MP.Basis.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "07d6e8b6-014e-4052-b5b6-3cd8f6ebde31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([0, 0, 1, 0, 0, 1, 0, 0, 1, 2, 0, 0, 2, 0, 0, 2, 1, 1, 2, 2, 2, 2, 0, 1, 2, 0, 1, 2, 2, 2, 2, 0, 0, 2, 1, 1, 2, 2, 2, 2, 0, 1, 2, 0, 1, 2, 2, 2, 2, 0, 0, 2, 1, 1, 2, 2, 2, 2, 0, 0, 2, 0, 0])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MP.dof_class.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d961648b-31e9-4e71-82d0-b4810694746f",
   "metadata": {},
   "outputs": [],
   "source": [
    "A, rhs = MP.assemble_system(vform.stiffness_vf(2), vform.L2functional_vf(2, physical=True), f=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4f8c96a1-a568-465e-8ca6-4620203feea1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 19)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c560ee79-36f1-4e95-92a7-e64ea49bb94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test case: T-junction itself\n",
    "#0, 1 and 2 are coarse dofs, 3, 4, 5 and 6, 7, 8 are fine dofs and 5 and 6 are also joined at the T-junction itself.\n",
    "constr = np.array([\n",
    "     [   1,  0,  0, -1,  0,  0,  0,  0,  0],\n",
    "     [  .5, .5,  0,  0, -1,  0,  0,  0,  0],\n",
    "     [   0,  1,  0,  0,  0, -1,  0,  0,  0],\n",
    "     [   0,  1,  0,  0,  0,  0, -1,  0,  0],\n",
    "     [   0, .5, .5,  0,  0,  0,  0, -1,  0],\n",
    "     [   0,  0,  1,  0,  0,  0,  0,  0, -1],\n",
    "     [   0,  0,  0,  0,  0,  1, -1,  0,  0]\n",
    "])\n",
    "#run_testcases(constr)\n",
    "\n",
    "ii = np.array([0,1,2,3,4,5,6,7,8])\n",
    "jj = np.random.permutation(9)\n",
    "#jj = np.array([0,1,2,3,4,5,6,7,8])\n",
    "v = np.ones(9)\n",
    "Q = scipy.sparse.coo_matrix((v,(ii,jj)),(9,9))\n",
    "constr=constr@Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "99d823c6-6f79-4ec9-ae9e-ddc880a592ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 4, 1, 6, 2, 8, 5, 7, 0])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5697a9f4-8218-4c3e-ae79-954f1444470e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 4, 1])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dofs=jj[np.array([0,1,2])]\n",
    "dofs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "119d528c-6865-4374-a50c-d54ab930948b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = basis_for_nullspace_of_dense_LU(constr, idx=dofs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "081e5ab7-f9dd-4655-8a17-4b67037421ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1. , 0. , 0. , 1. , 0.5, 0. , 0. , 0. , 0. ],\n",
       "       [0. , 1. , 0. , 0. , 0.5, 1. , 1. , 0.5, 0. ],\n",
       "       [0. , 0. , 1. , 0. , 0. , 0. , 0. , 0.5, 1. ]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat@Q.T #0,1,2 are coarse dofs after this backtransformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "id": "a5407319-e60c-4da4-ae9c-877dfd1e14bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 553,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat[:,dofs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "id": "2cebf409-8ff1-43f0-9a65-c1dacdd9550e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.  0.  0.  1.  0.5 0.  0.  0.  0. ]\n",
      " [0.  1.  0.  0.  0.5 1.  1.  0.5 0. ]\n",
      " [0.  0.  1.  0.  0.  0.  0.  0.5 1. ]]\n"
     ]
    }
   ],
   "source": [
    "S = scipy.linalg.solve(mat[:,dofs],mat)\n",
    "print(S@Q.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "610f302e-8109-4879-b00c-55eba8e3223c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1. , 0. , 0. , 1. , 0.5, 0. , 0. , 0. , 0. ],\n",
       "       [0. , 1. , 0. , 0. , 0.5, 1. , 1. , 0.5, 0. ],\n",
       "       [0. , 0. , 1. , 0. , 0. , 0. , 0. , 0.5, 1. ]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([[1/2,0,0],[0,1/2,0],[0,0,1]])@np.array([[1,0,0],[0,1,0],[0,1/2,1]])@np.array([[1,0,0],[1,1,0],[-1/2,0,1]])@mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e7cef67-1a9b-416c-9fd7-1cb8f4632b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "P,L,U = scipy.linalg.lu(constr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9948b6c6-ca26-4625-b9f3-eaaa2736309d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1. ,  0. ,  0. , -1. ,  0. ,  0. ,  0. ,  0. ,  0. ],\n",
       "       [ 0. ,  1. ,  0. ,  0. ,  0. , -1. ,  0. ,  0. ,  0. ],\n",
       "       [ 0. ,  0. ,  1. ,  0. ,  0. ,  0. ,  0. ,  0. , -1. ],\n",
       "       [ 0. ,  0. ,  0. ,  0.5, -1. ,  0.5,  0. ,  0. ,  0. ],\n",
       "       [ 0. ,  0. ,  0. ,  0. ,  0. ,  0.5,  0. , -1. ,  0.5],\n",
       "       [ 0. ,  0. ,  0. ,  0. ,  0. ,  1. , -1. ,  0. ,  0. ],\n",
       "       [ 0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "24bace60-7c9f-4629-98b8-11a74807fce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "A=np.random.rand(7,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "42e185f7-6813-4fa4-8e15-9bcb8816111b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.27243, 0.13322, 0.94188, 0.49573, 0.9828 , 0.99739, 0.39945, 0.72201, 0.92203],\n",
       "       [0.05158, 0.56389, 0.35291, 0.71488, 0.11822, 0.23313, 0.28333, 0.72939, 0.75654],\n",
       "       [0.09958, 0.01626, 0.17228, 0.3297 , 0.8473 , 0.69758, 0.68191, 0.98923, 0.29357],\n",
       "       [0.94399, 0.56185, 0.42673, 0.63615, 0.23987, 0.46015, 0.13805, 0.21679, 0.53555],\n",
       "       [0.32777, 0.19192, 0.43522, 0.76684, 0.41526, 0.59589, 0.6511 , 0.42693, 0.61985],\n",
       "       [0.49706, 0.14045, 0.89066, 0.03185, 0.44835, 0.32065, 0.45178, 0.62204, 0.99843],\n",
       "       [0.49594, 0.52433, 0.7516 , 0.4232 , 0.13252, 0.76609, 0.6551 , 0.8297 , 0.27639]])"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "eceecac4-70cc-4ccb-adfa-c1169f5c251c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.94188, 0.99739],\n",
       "       [0.35291, 0.23313],\n",
       "       [0.17228, 0.69758],\n",
       "       [0.42673, 0.46015],\n",
       "       [0.43522, 0.59589],\n",
       "       [0.89066, 0.32065],\n",
       "       [0.7516 , 0.76609]])"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A[:,np.array([2,5])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77899893-44cb-4906-86de-82fc558fcb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "A=np.arange(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e2e06e4-c22c-4168-9ee2-0bc5c157f2bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 0, 1, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A[np.array([0,1,1,0,0,1,0,1,0,1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8d50dd43-0a84-44a5-969b-67a695c6129d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fed53b20-69c5-4b32-99dd-d3c00215e2fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in range(10) if i==5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53deda68-2c07-442e-8c4f-212fe6351da9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
